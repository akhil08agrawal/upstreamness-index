{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please read the comments properly before executing the code\n",
    "# all the codes are in order hence the upper part must be taken care off properly\n",
    "# before proceeding to the further section of the code\n",
    "\n",
    "\n",
    "import zipfile\n",
    "# archive = zipfile.ZipFile('images.zip', 'r')\n",
    "# imgfile = archive.open('img_01.png')\n",
    "import scipy.linalg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from scipy.stats import mode\n",
    "import numpy.matlib\n",
    "\n",
    "def help():\n",
    "  print(\"List of functions\")\n",
    "  print(\"load_dataset(yyyy)\")\n",
    "  print(\"cross_country_IO_table(list_one , yyyy)\")\n",
    "  print(\"self_IO_table(country_code , yyyy)\")\n",
    "  print(\"get_upstream_value(country_code,yyyy)\")\n",
    "  print(\"get_industry_code() : To get the various labels data\")\n",
    "  print(\"save_weighted_UI_and_gross_output(commonwealth_countries,end_year , save_file ) : returns huha\")\n",
    "  print(\"    \")\n",
    "  print(\"the variables used\")\n",
    "  print(\"data_FD, data_Q, data_T,data_VA,data_QY , label_FD,label_Q,label_T,label_VA\")\n",
    "  print(\"country_codes, country_list,industry_codes_26,industry_codes_6\")\n",
    "  print(\"data_FD, data_Q, data_T,data_VA,data_QY \")  \n",
    "  print(\"label_FD,label_Q,label_T,label_VA \")\n",
    "  print(\"country_codes, country_list,industry_codes_26,industry_codes_6\")\n",
    "\n",
    "commonwealth_countries = ['ATG' , 'AUS' , 'BHS' , 'BGD' , 'BRB' , 'BLZ' , 'BWA' , 'BRN' , 'CMR' , 'CAN' , 'CYP' , 'DOM' , 'FJI' , 'GMB' , 'GHA' , 'GUY' , 'IND' , 'JAM' , 'KEN' , 'LSO' , 'MWI' , 'MYS' , 'MLT' , 'MUS' , 'MOZ' , 'NAM' , 'NZL' , 'NGA' , 'PAK' , 'PNG' , 'RWA' , 'WSM' , 'SYC' , 'SLE' , 'SGP' , 'ZAF' , 'LKA' , 'SWZ' , 'TTO' , 'UGA' , 'GBR' , 'VUT' , 'ZMB']\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset(yyyy):\n",
    "  file_name = \"Eora26_\" + str(yyyy) + \"_bp\" \n",
    "\n",
    "  # print(\"The data has been read from the directory\")\n",
    "  data = zipfile.ZipFile(file_name + '.zip','r')\n",
    "\n",
    "  data_FD = data.open(file_name + '_FD.txt')\n",
    "  data_Q = data.open(file_name + '_Q.txt')\n",
    "  data_T = data.open(file_name + '_T.txt')\n",
    "  data_VA = data.open(file_name + '_VA.txt')\n",
    "  data_QY = data.open(file_name + '_QY.txt')\n",
    "\n",
    "  label_FD = data.open('labels_FD.txt')\n",
    "  label_Q = data.open('labels_Q.txt')\n",
    "  label_T = data.open('labels_T.txt')\n",
    "  label_VA = data.open('labels_VA.txt')\n",
    "\n",
    "  data_FD = pd.read_csv( data_FD, sep=\"\\t\", header=None)\n",
    "  data_Q = pd.read_csv( data_Q, sep=\"\\t\", header=None)\n",
    "  data_T = pd.read_csv( data_T, sep=\"\\t\", header=None)\n",
    "  data_VA = pd.read_csv( data_VA, sep=\"\\t\", header=None)\n",
    "  data_QY = pd.read_csv( data_QY, sep=\"\\t\", header=None)\n",
    "\n",
    "  # label_FD = pd.read_csv( label_FD, sep=\"\\t\", header=None)\n",
    "  # label_Q = pd.read_csv( label_Q, sep=\"\\t\", header=None)\n",
    "  # label_T = pd.read_csv( label_T, sep=\"\\t\", header=None)\n",
    "  # label_VA = pd.read_csv( label_VA, sep=\"\\t\", header=None)\n",
    "\n",
    "  # delim_whitespace=True\n",
    "\n",
    "  label_FD = pd.read_csv( \"labels_FD.txt\", sep=\"\\t\", header=None)\n",
    "  label_Q = pd.read_csv( \"labels_Q.txt\", sep=\"\\t\", header=None)\n",
    "  label_T = pd.read_csv( \"labels_T.txt\", sep=\"\\t\", header=None)\n",
    "  label_VA = pd.read_csv( \"labels_VA.txt\", sep=\"\\t\", header=None)\n",
    "\n",
    "  # deleting useless column\n",
    "  # df = df.drop('column_name', 1)\n",
    "  labels = [label_FD , label_Q , label_T, label_VA]\n",
    "\n",
    "  label_FD = label_FD.drop(4,1)\n",
    "  label_Q = label_Q.drop(2,1)\n",
    "  label_T = label_T.drop(4,1)\n",
    "  label_VA = label_VA.drop(2,1)\n",
    "\n",
    "  country_codes = label_FD[1].unique()\n",
    "  # changing numpy array to list\n",
    "  country_codes = np.ndarray.tolist(country_codes)\n",
    "  # row_level_one = country_codes.index('CRI')\n",
    "\n",
    "  country_list = label_FD[0].unique()\n",
    "  # changing numpy array to list\n",
    "  country_list = np.ndarray.tolist(country_list)\n",
    "\n",
    "  industry_codes_26 = label_T[3].unique()\n",
    "  industry_codes_26 = np.ndarray.tolist(industry_codes_26)\n",
    "  industry_codes_26.remove('Total')\n",
    "\n",
    "  industry_codes_6 = label_FD[3].unique()\n",
    "  industry_codes_6 = np.ndarray.tolist(industry_codes_6)\n",
    "\n",
    "  return data_FD, data_Q, data_T,data_VA,data_QY , label_FD,label_Q,label_T,label_VA,country_codes, country_list,industry_codes_26,industry_codes_6\n",
    "\n",
    "\n",
    "# for just one country to country A-A\n",
    "def self_IO_table(country_code , yyyy):\n",
    "  # country_code = 'CHN'\n",
    "  # yyyy = '1990'\n",
    "  # print(\"Your table creation has started\")\n",
    "  data_FD, data_Q, data_T,data_VA,data_QY , label_FD,label_Q,label_T,label_VA,country_codes, country_list,industry_codes_26,industry_codes_6 = load_dataset(yyyy)\n",
    "  temp1 = data_T\n",
    "  temp2 = data_FD\n",
    "\n",
    "  row_level_one = country_codes.index(country_code)\n",
    "  # this gives us the index using which we can extract the data\n",
    "\n",
    "  #Now in temp 1 we just keep the coulumns starting from 6*row_level_one to 6 more columns and similarly for rows\n",
    "  # In temp 2 we also do the same\n",
    "\n",
    "  # Dimensions\n",
    "  #temp 1  == 4915 * 4915\n",
    "  # temp 2 == 4915 * 1140\n",
    "\n",
    "  # We have 26 industries and 6 dimensions in the FD\n",
    "\n",
    "  # Selecting and deleting the specific columns from the pandas dataframe\n",
    "\n",
    "  # # Using DataFrame.drop\n",
    "  # df.drop(df.columns[[1, 2]], axis=1, inplace=True)\n",
    "\n",
    "  # # drop by Name\n",
    "  # df1 = df1.drop(['B', 'C'], axis=1)\n",
    "\n",
    "  # # Select the ones you want\n",
    "  # df1 = df[['a','d']]\n",
    "\n",
    "      #Now to select certain percentage of rows from the given data\n",
    "      # df.iloc[(len(df)// 3) : (len(df)// 3 * 2), :]\n",
    "\n",
    "  temp1 = temp1.iloc[row_level_one: row_level_one+26 , :]\n",
    "  temp_col_26 = np.arange(row_level_one , row_level_one +26)\n",
    "  temp1 = temp1[temp_col_26]\n",
    "\n",
    "  temp2 = temp2.iloc[row_level_one: row_level_one+26 , :]\n",
    "  temp_col_6 = np.arange(row_level_one , row_level_one +6)\n",
    "  temp2 = temp2[temp_col_6]\n",
    "\n",
    "  # io_table = pd.DataFrame.add(temp1 , temp2)\n",
    "  io_table = pd.concat([temp1, temp2] , axis = 1 , ignore_index= True )\n",
    "  # io_table = temp1 + temp2\n",
    "  # io_table.shape  == 26 *32\n",
    "\n",
    "  # changing the column names to a list\n",
    "  # adding the appropriate columns names\n",
    "  io_table.columns = industry_codes_26 + industry_codes_6\n",
    "\n",
    "  #Changing both the column and the row indexes\n",
    "\n",
    "  # gapminder.rename(columns={'lifeExp':'life_exp'}, \n",
    "  #                  index={0:'zero',1:'one'}, \n",
    "  #                  inplace=True)\n",
    "  io_table[country_code] = industry_codes_26\n",
    "  # Now how to change the order of columns in the pandas dataframe\n",
    "  # cols = cols[-1:] + cols[:-1]\n",
    "  # cols\n",
    "  # df = df[cols]  #    OR    df = df.ix[:, cols]\n",
    "  cols = list(io_table.columns.values)\n",
    "  cols = cols[-1:] + cols[:-1]\n",
    "  io_table = io_table[cols]\n",
    "\n",
    "  # Saving to csv\n",
    "  #temp.to_csv(\"The_Imperfects_IITKgp_\" + str(submission_number) +\".csv\",header= False , index = False)\n",
    "  filename = str(yyyy) +  \"_\" +str(country_code) + \"_\"  + \"I_O_table\" +  \".csv\"\n",
    "  io_table.to_csv(filename, index = False ) \n",
    "  print(\"Congrats, your file has been saved and the name of the file is below\")\n",
    "  print(filename)\n",
    "  print(\"You can find the file in the mtp_data folder in the google drive\")\n",
    "  print(\"Please delete the final after use, as we have limited space available on the goolge drive\")\n",
    "  print(\"To delete the file just created simply run the line of code in the next cell\")\n",
    "  return filename\n",
    "  \n",
    "\n",
    "def cross_country_IO_table(list_one , yyyy):\n",
    "\n",
    "  # list_one = ['IND' , 'AUS' , 'CHN']\n",
    "  # print(\"Your table creation has started\")\n",
    "  data_FD, data_Q, data_T,data_VA,data_QY , label_FD,label_Q,label_T,label_VA,country_codes, country_list,industry_codes_26,industry_codes_6 = load_dataset(yyyy)\n",
    "  important_index_26 = []\n",
    "  important_index_6 = []\n",
    "\n",
    "  for data_ in list_one:\n",
    "    # print(data_)\n",
    "    row_level_one = country_codes.index(data_)\n",
    "    # print(row_level_one)\n",
    "    temp_26 = np.arange(row_level_one*26 , row_level_one*26 +26)\n",
    "    temp_26 = np.ndarray.tolist(temp_26)           \n",
    "    important_index_26 = important_index_26 + temp_26\n",
    "\n",
    "    temp_6 = np.arange(row_level_one*6 , row_level_one*6 +6)\n",
    "    temp_6 = np.ndarray.tolist(temp_6)           \n",
    "    important_index_6 = important_index_6 + temp_6\n",
    "\n",
    "  temp1 = data_T\n",
    "  temp2 = data_FD\n",
    "\n",
    "  # selecting specific columns\n",
    "  temp1 = temp1[important_index_26]\n",
    "  temp1 =temp1.iloc[important_index_26,]\n",
    "\n",
    "  temp2 = temp2[important_index_6]\n",
    "  temp2 =temp2.iloc[important_index_26,]\n",
    "\n",
    "  length_of_list = len(list_one)\n",
    "  industry_codes_26 = industry_codes_26 *length_of_list\n",
    "  industry_codes_6 = industry_codes_6 *length_of_list\n",
    "\n",
    "  # io_table = pd.DataFrame.add(temp1 , temp2)\n",
    "  io_table = pd.concat([temp1, temp2] , axis = 1 , ignore_index= True )\n",
    "    # io_table = temp1 + temp2\n",
    "    # io_table.shape  == 26 *32\n",
    "\n",
    "    # changing the column names to a list\n",
    "    # adding the appropriate columns names\n",
    "  io_table.columns = industry_codes_26 + industry_codes_6\n",
    "\n",
    "    #Changing both the column and the row indexes\n",
    "\n",
    "\n",
    "    # gapminder.rename(columns={'lifeExp':'life_exp'}, \n",
    "    #                  index={0:'zero',1:'one'}, \n",
    "    #                  inplace=True)\n",
    "  io_table[\"country_code\"] = industry_codes_26\n",
    "\n",
    "    # Now how to change the order of columns in the pandas dataframe\n",
    "    # cols = cols[-1:] + cols[:-1]\n",
    "    # cols\n",
    "    # df = df[cols]  #    OR    df = df.ix[:, cols]\n",
    "  cols = list(io_table.columns.values)\n",
    "  cols = cols[-1:] + cols[:-1]\n",
    "  io_table = io_table[cols]\n",
    "\n",
    "    # Saving to csv\n",
    "    # io_table.to_csv(\"The_Imperfects_IITKgp_\" + str(submission_number) +\".csv\",header= False , index = False)\n",
    "  filename = str(yyyy) + \"_\" + \"cross_country\" + str(length_of_list) + str(list_one[0]) + str(list_one[1]) +  \"_\"  + \"I_O_table\" +  \".csv\"\n",
    "  io_table.to_csv(filename, index = False ) \n",
    "  print(\"Congrats, your file has been saved and the name of the file is below\")\n",
    "  print(filename)\n",
    "  print(\"You can find the file in the mtp_data folder in the google drive\")\n",
    "  print(\"Please delete the final after use, as we have limited space available on the goolge drive\")\n",
    "  print(\"To delete the file just created simply run the line of code in the next cell\")\n",
    "  return filename\n",
    "\n",
    "\n",
    "def get_industry_code(yyyy = 1990):\n",
    "  file_name = \"Eora26_\" + str(yyyy) + \"_bp\" \n",
    "\n",
    "  # print(\"The data has been read from the directory\")\n",
    "  data = zipfile.ZipFile(file_name + '.zip','r')\n",
    "\n",
    "#   data_FD = data.open(file_name + '_FD.txt')\n",
    "#   data_Q = data.open(file_name + '_Q.txt')\n",
    "#   data_T = data.open(file_name + '_T.txt')\n",
    "#   data_VA = data.open(file_name + '_VA.txt')\n",
    "#   data_QY = data.open(file_name + '_QY.txt')\n",
    "\n",
    "  label_FD = data.open('labels_FD.txt')\n",
    "  label_Q = data.open('labels_Q.txt')\n",
    "  label_T = data.open('labels_T.txt')\n",
    "  label_VA = data.open('labels_VA.txt')\n",
    "\n",
    "#   data_FD = pd.read_csv( data_FD, sep=\"\\t\", header=None)\n",
    "#   data_Q = pd.read_csv( data_Q, sep=\"\\t\", header=None)\n",
    "#   data_T = pd.read_csv( data_T, sep=\"\\t\", header=None)\n",
    "#   data_VA = pd.read_csv( data_VA, sep=\"\\t\", header=None)\n",
    "#   data_QY = pd.read_csv( data_QY, sep=\"\\t\", header=None)\n",
    "\n",
    "  # label_FD = pd.read_csv( label_FD, sep=\"\\t\", header=None)\n",
    "  # label_Q = pd.read_csv( label_Q, sep=\"\\t\", header=None)\n",
    "  # label_T = pd.read_csv( label_T, sep=\"\\t\", header=None)\n",
    "  # label_VA = pd.read_csv( label_VA, sep=\"\\t\", header=None)\n",
    "\n",
    "  # delim_whitespace=True\n",
    "\n",
    "  label_FD = pd.read_csv( \"labels_FD.txt\", sep=\"\\t\", header=None)\n",
    "  label_Q = pd.read_csv( \"labels_Q.txt\", sep=\"\\t\", header=None)\n",
    "  label_T = pd.read_csv( \"labels_T.txt\", sep=\"\\t\", header=None)\n",
    "  label_VA = pd.read_csv( \"labels_VA.txt\", sep=\"\\t\", header=None)\n",
    "\n",
    "  # deleting useless column\n",
    "  # df = df.drop('column_name', 1)\n",
    "  labels = [label_FD , label_Q , label_T, label_VA]\n",
    "\n",
    "  label_FD = label_FD.drop(4,1)\n",
    "  label_Q = label_Q.drop(2,1)\n",
    "  label_T = label_T.drop(4,1)\n",
    "  label_VA = label_VA.drop(2,1)\n",
    "\n",
    "  country_codes = label_FD[1].unique()\n",
    "  # changing numpy array to list\n",
    "  country_codes = np.ndarray.tolist(country_codes)\n",
    "  # row_level_one = country_codes.index('CRI')\n",
    "\n",
    "  country_list = label_FD[0].unique()\n",
    "  # changing numpy array to list\n",
    "  country_list = np.ndarray.tolist(country_list)\n",
    "\n",
    "  industry_codes_26 = label_T[3].unique()\n",
    "  industry_codes_26 = np.ndarray.tolist(industry_codes_26)\n",
    "  industry_codes_26.remove('Total')\n",
    "\n",
    "  industry_codes_6 = label_FD[3].unique()\n",
    "  industry_codes_6 = np.ndarray.tolist(industry_codes_6)\n",
    "\n",
    "  return country_codes, country_list,industry_codes_26,industry_codes_6 , label_Q , label_VA\n",
    "\n",
    "\n",
    "def get_upstream_value(country_code,yyyy):\n",
    "    \n",
    "    data_FD, data_T,country_codes, country_list,industry_codes_26,industry_codes_6 = load_dataset_2(yyyy)\n",
    "    data_FD, data_Q, data_T,data_VA,data_QY , label_FD,label_Q,label_T,label_VA,country_codes, country_list,industry_codes_26,industry_codes_6 = load_dataset(yyyy)\n",
    "    temp1 = data_T.copy()\n",
    "    temp2 = data_FD.copy()\n",
    "\n",
    "    row_level_one = country_codes.index(country_code)\n",
    "\n",
    "    temp1 = temp1.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    \"\"\" multiplying by 26 as for a particular country the self IO table just needs the 26 rows starting from the row number \n",
    "    row_level_one * 26 because there are total 26 industries\"\"\"\n",
    "    temp_col_26 = np.arange(row_level_one*26, row_level_one*26 +26)\n",
    "    temp1 = temp1[temp_col_26]\n",
    "\n",
    "    temp2 = temp2.iloc[row_level_one*26: row_level_one*26+26 , :]\n",
    "    temp_col_6 = np.arange(row_level_one*6 , row_level_one*6 +6)\n",
    "    temp2 = temp2[temp_col_6]\n",
    "\n",
    "    data = pd.concat([temp1, temp2] , axis = 1 , ignore_index= True )\n",
    "    data.columns = industry_codes_26 + industry_codes_6\n",
    "    c = data.columns\n",
    "    data[\"Total_use\"] = 0\n",
    "\n",
    "    for c in c:\n",
    "        data[\"Total_use\"] = data[\"Total_use\"] + data[c]\n",
    "    # io_table\n",
    "\n",
    "    data[country_code] = industry_codes_26\n",
    "\n",
    "    cols = list(data.columns.values)\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    data = data[cols]\n",
    "\n",
    "#     data = io_table.copy()\n",
    "    gross_output = data['Total_use']\n",
    "\n",
    "    # renaming data columns\n",
    "    #changing column name : columns name\n",
    "\n",
    "    data = data.rename(columns={\"Agriculture\": \"c1\" ,\"Fishing\": \"c2\" , \"Mining and Quarrying\": \"c3\" ,\"Food & Beverages\": \"c4\" ,\n",
    "                               \"Textiles and Wearing Apparel\": \"c5\" ,\"Wood and Paper\": \"c6\" ,\n",
    "                                \"Petroleum, Chemical and Non-Metallic Mineral Products\": \"c7\" ,\"Metal Products\": \"c8\" ,\n",
    "                               \"Electrical and Machinery\": \"c9\" ,\"Transport Equipment\": \"c10\" , \"Other Manufacturing\": \"c11\" \n",
    "                                ,\"Recycling\": \"c12\" ,\n",
    "                               \"Electricity, Gas and Water\": \"c13\" ,\"Construction\": \"c14\" , \"Maintenance and Repair\": \"c15\" \n",
    "                                ,\"Wholesale Trade\": \"c16\" ,\n",
    "                               \"Retail Trade\" : \"c17\" , \"Hotels and Restraurants\": \"c18\" , \"Transport\": \"c19\" \n",
    "                                ,\"Post and Telecommunications\": \"c20\" ,\n",
    "                               \"Finacial Intermediation and Business Activities\": \"c21\" \n",
    "                                , \"Public Administration\": \"c22\" ,\"Education, Health and Other Services\": \"c23\" ,\n",
    "                               \"Private Households\": \"c24\" ,\"Others\": \"c25\" ,\"Re-export & Re-import\": \"c26\" })\n",
    "\n",
    "    data = data.rename(columns={\"Household final consumption P.3h\": \"f1\" ,\"Non-profit institutions serving households P.3n\": \"f2\" ,\n",
    "                                \"Government final consumption P.3g\": \"f3\" ,\"Gross fixed capital formation P.51\": \"f4\" ,\n",
    "                               \"Changes in inventories P.52\": \"f5\" ,\"Acquisitions less disposals of valuables P.53\": \"f6\"  })\n",
    "\n",
    "\n",
    "    list_of_c1_to_c26 = []\n",
    "    for i in range(1,27):\n",
    "      list_of_c1_to_c26.append(\"c\"+str(i))\n",
    "\n",
    "    list_of_f1_to_f6 = []\n",
    "    for i in range(1,7):\n",
    "      list_of_f1_to_f6.append(\"c\"+str(i))\n",
    "\n",
    "    for c in list_of_c1_to_c26:\n",
    "        data[c] = data[c]/data['Total_use']\n",
    "\n",
    "    data = data[[c for c in data.columns if c in list_of_c1_to_c26]]\n",
    "\n",
    "    I = np.identity(26)\n",
    "    # one_vector = np.ones(35)\n",
    "    one_vector = np.ones(26).reshape((26, 1))\n",
    "\n",
    "    # We use numpy.linalg.inv() function to calculate the inverse of a matrix.\n",
    "\n",
    "    temp = I - data\n",
    "    temp2 = np.linalg.inv(temp)\n",
    "    upstream_value = np.matmul(temp2,one_vector)\n",
    "    \n",
    "    return upstream_value\n",
    "\n",
    "def load_dataset_2(yyyy):\n",
    "  file_name = \"Eora26_\" + str(yyyy) + \"_bp\" \n",
    "\n",
    "  # print(\"The data has been read from the directory\")\n",
    "  data = zipfile.ZipFile(file_name + '.zip','r')\n",
    "\n",
    "  data_FD = data.open(file_name + '_FD.txt')\n",
    "#   data_Q = data.open(file_name + '_Q.txt')\n",
    "  data_T = data.open(file_name + '_T.txt')\n",
    "#   data_VA = data.open(file_name + '_VA.txt')\n",
    "#   data_QY = data.open(file_name + '_QY.txt')\n",
    "\n",
    "  label_FD = data.open('labels_FD.txt')\n",
    "  label_Q = data.open('labels_Q.txt')\n",
    "  label_T = data.open('labels_T.txt')\n",
    "  label_VA = data.open('labels_VA.txt')\n",
    "\n",
    "  data_FD = pd.read_csv( data_FD, sep=\"\\t\", header=None)\n",
    "#   data_Q = pd.read_csv( data_Q, sep=\"\\t\", header=None)\n",
    "  data_T = pd.read_csv( data_T, sep=\"\\t\", header=None)\n",
    "#   data_VA = pd.read_csv( data_VA, sep=\"\\t\", header=None)\n",
    "#   data_QY = pd.read_csv( data_QY, sep=\"\\t\", header=None)\n",
    "\n",
    "  # label_FD = pd.read_csv( label_FD, sep=\"\\t\", header=None)\n",
    "  # label_Q = pd.read_csv( label_Q, sep=\"\\t\", header=None)\n",
    "  # label_T = pd.read_csv( label_T, sep=\"\\t\", header=None)\n",
    "  # label_VA = pd.read_csv( label_VA, sep=\"\\t\", header=None)\n",
    "\n",
    "  # delim_whitespace=True\n",
    "\n",
    "  label_FD = pd.read_csv( \"labels_FD.txt\", sep=\"\\t\", header=None)\n",
    "  label_Q = pd.read_csv( \"labels_Q.txt\", sep=\"\\t\", header=None)\n",
    "  label_T = pd.read_csv( \"labels_T.txt\", sep=\"\\t\", header=None)\n",
    "  label_VA = pd.read_csv( \"labels_VA.txt\", sep=\"\\t\", header=None)\n",
    "\n",
    "  # deleting useless column\n",
    "  # df = df.drop('column_name', 1)\n",
    "  labels = [label_FD , label_Q , label_T, label_VA]\n",
    "\n",
    "  label_FD = label_FD.drop(4,1)\n",
    "  label_Q = label_Q.drop(2,1)\n",
    "  label_T = label_T.drop(4,1)\n",
    "  label_VA = label_VA.drop(2,1)\n",
    "\n",
    "  country_codes = label_FD[1].unique()\n",
    "  # changing numpy array to list\n",
    "  country_codes = np.ndarray.tolist(country_codes)\n",
    "  # row_level_one = country_codes.index('CRI')\n",
    "\n",
    "  country_list = label_FD[0].unique()\n",
    "  # changing numpy array to list\n",
    "  country_list = np.ndarray.tolist(country_list)\n",
    "\n",
    "  industry_codes_26 = label_T[3].unique()\n",
    "  industry_codes_26 = np.ndarray.tolist(industry_codes_26)\n",
    "  industry_codes_26.remove('Total')\n",
    "\n",
    "  industry_codes_6 = label_FD[3].unique()\n",
    "  industry_codes_6 = np.ndarray.tolist(industry_codes_6)\n",
    "\n",
    "  return data_FD, data_T,country_codes, country_list,industry_codes_26,industry_codes_6\n",
    "\n",
    "\n",
    "\n",
    "def weighted_upstream_value_for_country(country_code,yyyy):\n",
    "    \n",
    "    data_FD, data_T,country_codes, country_list,industry_codes_26,industry_codes_6 = load_dataset_2(yyyy)\n",
    "    temp1 = data_T.copy()\n",
    "    temp2 = data_FD.copy()\n",
    "\n",
    "    row_level_one = country_codes.index(country_code)\n",
    "\n",
    "    temp1 = temp1.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    \"\"\" multiplying by 26 as for a particular country the self IO table just needs the 26 rows starting from the row number \n",
    "    row_level_one * 26 because there are total 26 industries\"\"\"\n",
    "    temp_col_26 = np.arange(row_level_one*26, row_level_one*26 +26)\n",
    "    temp1 = temp1[temp_col_26]\n",
    "\n",
    "    temp2 = temp2.iloc[row_level_one*26: row_level_one*26+26 , :]\n",
    "    temp_col_6 = np.arange(row_level_one*6 , row_level_one*6 +6)\n",
    "    temp2 = temp2[temp_col_6]\n",
    "\n",
    "    data = pd.concat([temp1, temp2] , axis = 1 , ignore_index= True )\n",
    "    data.columns = industry_codes_26 + industry_codes_6\n",
    "    c = data.columns\n",
    "    data[\"Total_use\"] = 0\n",
    "\n",
    "    for c in c:\n",
    "        data[\"Total_use\"] = data[\"Total_use\"] + data[c]\n",
    "    # io_table\n",
    "\n",
    "    data[country_code] = industry_codes_26\n",
    "\n",
    "    cols = list(data.columns.values)\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    data = data[cols]\n",
    "\n",
    "#     data = io_table.copy()\n",
    "    gross_output = data['Total_use']\n",
    "    gross_output_2 = data['Total_use']\n",
    "\n",
    "    # renaming data columns\n",
    "    #changing column name : columns name\n",
    "\n",
    "    data = data.rename(columns={\"Agriculture\": \"c1\" ,\"Fishing\": \"c2\" , \"Mining and Quarrying\": \"c3\" ,\"Food & Beverages\": \"c4\" ,\n",
    "                               \"Textiles and Wearing Apparel\": \"c5\" ,\"Wood and Paper\": \"c6\" ,\n",
    "                                \"Petroleum, Chemical and Non-Metallic Mineral Products\": \"c7\" ,\"Metal Products\": \"c8\" ,\n",
    "                               \"Electrical and Machinery\": \"c9\" ,\"Transport Equipment\": \"c10\" , \"Other Manufacturing\": \"c11\" \n",
    "                                ,\"Recycling\": \"c12\" ,\n",
    "                               \"Electricity, Gas and Water\": \"c13\" ,\"Construction\": \"c14\" , \"Maintenance and Repair\": \"c15\" \n",
    "                                ,\"Wholesale Trade\": \"c16\" ,\n",
    "                               \"Retail Trade\" : \"c17\" , \"Hotels and Restraurants\": \"c18\" , \"Transport\": \"c19\" \n",
    "                                ,\"Post and Telecommunications\": \"c20\" ,\n",
    "                               \"Finacial Intermediation and Business Activities\": \"c21\" \n",
    "                                , \"Public Administration\": \"c22\" ,\"Education, Health and Other Services\": \"c23\" ,\n",
    "                               \"Private Households\": \"c24\" ,\"Others\": \"c25\" ,\"Re-export & Re-import\": \"c26\" })\n",
    "\n",
    "    data = data.rename(columns={\"Household final consumption P.3h\": \"f1\" ,\"Non-profit institutions serving households P.3n\": \"f2\" ,\n",
    "                                \"Government final consumption P.3g\": \"f3\" ,\"Gross fixed capital formation P.51\": \"f4\" ,\n",
    "                               \"Changes in inventories P.52\": \"f5\" ,\"Acquisitions less disposals of valuables P.53\": \"f6\"  })\n",
    "\n",
    "\n",
    "    list_of_c1_to_c26 = []\n",
    "    for i in range(1,27):\n",
    "      list_of_c1_to_c26.append(\"c\"+str(i))\n",
    "\n",
    "    list_of_f1_to_f6 = []\n",
    "    for i in range(1,7):\n",
    "      list_of_f1_to_f6.append(\"c\"+str(i))\n",
    "\n",
    "    for c in list_of_c1_to_c26:\n",
    "        data[c] = data[c]/data['Total_use']\n",
    "\n",
    "    data = data[[c for c in data.columns if c in list_of_c1_to_c26]]\n",
    "\n",
    "    I = np.identity(26)\n",
    "    # one_vector = np.ones(35)\n",
    "    one_vector = np.ones(26).reshape((26, 1))\n",
    "\n",
    "    # We use numpy.linalg.inv() function to calculate the inverse of a matrix.\n",
    "\n",
    "    temp = I - data\n",
    "    temp2 = np.linalg.inv(temp)\n",
    "    upstream_value = np.matmul(temp2,one_vector)\n",
    "    \n",
    "    upstream_value_transpose = upstream_value.reshape((1,26))\n",
    "    gross_output_total = 0\n",
    "    for i in range(row_level_one*26,row_level_one*26+26):\n",
    "        gross_output_total = gross_output_total + gross_output[i]\n",
    "    \n",
    "    gross_output = gross_output / gross_output_total\n",
    "\n",
    "    total_weight = 0\n",
    "    for i in range(row_level_one*26,row_level_one*26+26):\n",
    "        total_weight = total_weight + gross_output[i]\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Total weight is \", total_weight)\n",
    "\n",
    "    weighted_upstream_value_for_country = np.matmul(upstream_value_transpose,gross_output)\n",
    "    \n",
    "    \n",
    "    return float(weighted_upstream_value_for_country), gross_output_2 \n",
    "\n",
    "\n",
    "\n",
    "def save_weighted_UI_and_gross_output(commonwealth_countries,end_year , save_file ):\n",
    "#     commonwealth_countries = ['ATG' , 'AUS' , 'BHS' , 'BGD' , 'BRB' , 'BLZ' , 'BWA' , 'BRN' , 'CMR' , 'CAN' , 'CYP' , 'DOM' , 'FJI' , 'GMB' , 'GHA' , 'GUY' , 'IND' , 'JAM' , 'KEN' , 'LSO' , 'MWI' , 'MYS' , 'MLT' , 'MUS' , 'MOZ' , 'NAM' , 'NZL' , 'NGA' , 'PAK' , 'PNG' , 'RWA' , 'WSM' , 'SYC' , 'SLE' , 'SGP' , 'ZAF' , 'LKA' , 'SWZ' , 'TTO' , 'UGA' , 'GBR' , 'VUT' , 'ZMB']\n",
    "    # commonwealth_countries = ['ATG', 'AUS']\n",
    "    start = datetime.now()\n",
    "    start_year = 1990\n",
    "#     end_year = 2015\n",
    "\n",
    "    year_timeline = []\n",
    "    for i in range(start_year,end_year+1):\n",
    "        year_timeline.append(i)\n",
    "#     print(year_timeline)\n",
    "\n",
    "    huha = pd.DataFrame(year_timeline)\n",
    "\n",
    "    #get industry codes 26\n",
    "    country_codes, country_list,industry_codes_26,industry_codes_6 , label_Q, label_VA = get_industry_code()\n",
    "\n",
    "    for c in commonwealth_countries:\n",
    "        print(\"\")\n",
    "        print(\"//////////////////////////////\")\n",
    "        print(\"the country in progress is \",c)\n",
    "        print(\"\")\n",
    "        temp_list = []\n",
    "        pd_gross_output = pd.DataFrame(industry_codes_26)\n",
    "        #Rename the index 0 to the country code\n",
    "        pd_gross_output = pd_gross_output.rename(columns = {0 : c})\n",
    "\n",
    "        for yyyy in range(start_year,end_year+1):\n",
    "            print(\"the year is \", yyyy)\n",
    "            a,gross_output  = weighted_upstream_value_for_country(c,yyyy)\n",
    "            pd_gross_output[yyyy] = gross_output\n",
    "            print(a)\n",
    "            temp_list.append(a)\n",
    "            print(\"temp_list\")\n",
    "            print(temp_list)\n",
    "\n",
    "        huha[c] = temp_list\n",
    "        print(\"The country completed is \", c)\n",
    "        huha.to_csv(\"temp_so_far_\"+str(c)+\".csv\", index= False)\n",
    "        if(save_file == 1):\n",
    "            pd_gross_output.to_csv(str(c) + \"_gross_output.csv\", index = False)\n",
    "        if(save_file == 3):\n",
    "            pd_gross_output.to_csv(str(c) + \"_gross_output.csv\", index = False)\n",
    "        \n",
    "\n",
    "    end = datetime.now()\n",
    "    if(save_file == 2):\n",
    "        huha.to_csv(\"Final_weighted_avg_UI_country_wise.csv\", index = False)\n",
    "    if(save_file == 3):\n",
    "        huha.to_csv(\"Final_weighted_avg_UI_country_wise.csv\", index = False)\n",
    "    print(\"the time taken is \", end-start)\n",
    "    \n",
    "    return huha\n",
    "\n",
    "def open_economy_UI_index(country_code,yyyy):\n",
    "    data_FD, data_Q, data_T,data_VA,data_QY , label_FD,label_Q,label_T,label_VA,country_codes, country_list,industry_codes_26,industry_codes_6 = load_dataset(yyyy)\n",
    "    # temp1 = data_T.copy()\n",
    "    data_T_for_X = data_T.copy()\n",
    "    # data_T_for_Y = data_T.copy()\n",
    "    temp2 = data_FD.copy()\n",
    "    # data_FD_for_Y = data_FD.copy()\n",
    "\n",
    "    row_level_one = country_codes.index(country_code)\n",
    "\n",
    "    data_T = data_T.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    \"\"\" multiplying by 26 as for a particular country the self IO table just needs the 26 rows starting from the row number \n",
    "    row_level_one * 26 because there are total 26 industries\"\"\"\n",
    "    temp_col_26 = np.arange(row_level_one*26, row_level_one*26 +26)\n",
    "    data_T = data_T[temp_col_26]\n",
    "    temp1= data_T.copy()\n",
    "\n",
    "    temp2 = temp2.iloc[row_level_one*26: row_level_one*26+26 , :]\n",
    "    temp_col_6 = np.arange(row_level_one*6 , row_level_one*6 +6)\n",
    "    temp2 = temp2[temp_col_6]\n",
    "\n",
    "    data = pd.concat([temp1, temp2] , axis = 1 , ignore_index= True )\n",
    "    data.columns = industry_codes_26 + industry_codes_6\n",
    "    c = data.columns\n",
    "    # #io_table[\"Total_use\"] = 0\n",
    "\n",
    "\n",
    "    # for c in c:\n",
    "    #     io_table[\"Total_use\"] = io_table[\"Total_use\"] + io_table[c]\n",
    "    # io_table\n",
    "\n",
    "    data[country_code] = industry_codes_26\n",
    "\n",
    "    cols = list(data.columns.values)\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    data = data[cols]\n",
    "\n",
    "\n",
    "    # renaming data columns\n",
    "\n",
    "    data = data.rename(columns={\"Agriculture\": \"c1\" ,\"Fishing\": \"c2\" , \"Mining and Quarrying\": \"c3\" ,\"Food & Beverages\": \"c4\" ,\n",
    "                               \"Textiles and Wearing Apparel\": \"c5\" ,\"Wood and Paper\": \"c6\" ,\n",
    "                                \"Petroleum, Chemical and Non-Metallic Mineral Products\": \"c7\" ,\"Metal Products\": \"c8\" ,\n",
    "                               \"Electrical and Machinery\": \"c9\" ,\"Transport Equipment\": \"c10\" , \"Other Manufacturing\": \"c11\" \n",
    "                                ,\"Recycling\": \"c12\" ,\n",
    "                               \"Electricity, Gas and Water\": \"c13\" ,\"Construction\": \"c14\" , \"Maintenance and Repair\": \"c15\" \n",
    "                                ,\"Wholesale Trade\": \"c16\" ,\n",
    "                               \"Retail Trade\" : \"c17\" , \"Hotels and Restraurants\": \"c18\" , \"Transport\": \"c19\" \n",
    "                                ,\"Post and Telecommunications\": \"c20\" ,\n",
    "                               \"Finacial Intermediation and Business Activities\": \"c21\" \n",
    "                                , \"Public Administration\": \"c22\" ,\"Education, Health and Other Services\": \"c23\" ,\n",
    "                               \"Private Households\": \"c24\" ,\"Others\": \"c25\" ,\"Re-export & Re-import\": \"c26\" })\n",
    "\n",
    "    data = data.rename(columns={\"Household final consumption P.3h\": \"f1\" ,\"Non-profit institutions serving households P.3n\": \"f2\" ,\n",
    "                                \"Government final consumption P.3g\": \"f3\" ,\"Gross fixed capital formation P.51\": \"f4\" ,\n",
    "                               \"Changes in inventories P.52\": \"f5\" ,\"Acquisitions less disposals of valuables P.53\": \"f6\"  })\n",
    "\n",
    "\n",
    "    list_of_c1_to_c26 = []\n",
    "    for i in range(1,27):\n",
    "      list_of_c1_to_c26.append(\"c\"+str(i))\n",
    "\n",
    "    list_of_f1_to_f6 = []\n",
    "    for i in range(1,7):\n",
    "      list_of_f1_to_f6.append(\"c\"+str(i))\n",
    "\n",
    "    # Import and export calculation\n",
    "\n",
    "    #IMPORT calculation\n",
    "\n",
    "    #temp1 = data_T\n",
    "    # temp_col_26\n",
    "\n",
    "    # data_T = data_T[temp_col_26]\n",
    "\n",
    "    temp_sum = []\n",
    "    total_sum_import_1 = []\n",
    "    for i in temp_col_26:\n",
    "        temp_sum.append(temp1[i].sum())\n",
    "        total_sum_import_1.append(data_T[i].sum())\n",
    "    #vertical addition   \n",
    "\n",
    "    # for i in temp_col_6:\n",
    "    #     total_sum_import_2.append(data_FD[i].sum())\n",
    "    #     print(i)\n",
    "\n",
    "    #Not including this as we only care if the data is corresponding to the industry level given a single country\n",
    "    # They are definitely importing something directing in the final demand section from different countries but not at \n",
    "    #      industry section level\n",
    "    # Though for the calculation of the export data both would be considered\n",
    "\n",
    "    temp_sum = np.asarray(temp_sum)\n",
    "    total_sum_import_1 = np.asarray(total_sum_import_1)\n",
    "\n",
    "    imports_1 = total_sum_import_1 - temp_sum\n",
    "#     print(\"\")\n",
    "#     print(imports_1)\n",
    "\n",
    "    # Exports - calculating exports\n",
    "\n",
    "    # temp2 = data_FD   4915 x 1140\n",
    "\n",
    "    data_T_for_X = data_T_for_X.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    data_T_for_X = data_T_for_X.drop(columns = [4914])\n",
    "    total_export_sum_1 = np.sum(data_T_for_X , axis=1).tolist()\n",
    "    total_export_sum_1 = np.asarray(total_export_sum_1)\n",
    "\n",
    "    temp_export_sum_1 = np.sum(temp1,axis=1).tolist()\n",
    "    temp_export_sum_1 = np.asarray(temp_export_sum_1)\n",
    "\n",
    "    export_sum_1 = total_export_sum_1 - temp_export_sum_1\n",
    "#     print(\"\")\n",
    "#     print(export_sum_1)\n",
    "\n",
    "\n",
    "    data_FD = data_FD.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    data_FD = data_FD.drop(columns = [1134,1135,1136,1137,1138,1139])\n",
    "    total_export_sum_2 = np.sum(data_FD , axis=1).tolist()         # 1134 columns\n",
    "    total_export_sum_2 = np.asarray(total_export_sum_2)\n",
    "\n",
    "    temp_export_sum_2 = np.sum(temp2,axis=1).tolist()            # 6 columns\n",
    "    temp_export_sum_2 = np.asarray(temp_export_sum_2)\n",
    "\n",
    "    export_sum_2 = total_export_sum_2 - temp_export_sum_2\n",
    "\n",
    "#     print(\"\")\n",
    "#     print(export_sum_2)\n",
    "\n",
    "    export_sum = export_sum_1 + export_sum_2\n",
    "#     print(\"\")\n",
    "#     print(export_sum)\n",
    "\n",
    "\n",
    "    net_exports = export_sum - imports_1\n",
    "\n",
    "    # gross_output = data['Total_use']\n",
    "    # Calculating the gross output from the complete data\n",
    "    # We need one more set of data_T and data_FD\n",
    "\n",
    "    #data_T_row-wise total\n",
    "\n",
    "    # data_T_for_Y = data_T_for_Y.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    # data_T_for_Y = data_T_for_Y.drop(columns = [4914])\n",
    "    # gross_output_1 = np.sum(data_T_for_Y , axis=1).tolist()\n",
    "    # gross_output_1 = np.asarray(gross_output_1)\n",
    "\n",
    "    # data_FD_for_Y = data_FD_for_Y.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    # data_FD_for_Y = data_FD_for_Y.drop(columns = [1134,1135,1136,1137,1138,1139])\n",
    "    # gross_output_2 = np.sum(data_FD_for_Y , axis=1).tolist()         # 1134 columns\n",
    "    # gross_output_2 = np.asarray(gross_output_2)\n",
    "\n",
    "    gross_output = total_export_sum_1 + total_export_sum_2\n",
    "\n",
    "    temp_numerator = gross_output.copy()\n",
    "    temp_denominator = gross_output - net_exports\n",
    "    temp_multiplier = temp_numerator / temp_denominator\n",
    "\n",
    "    #Modifying the Dij values\n",
    "\n",
    "    data = data[[c for c in data.columns if c in list_of_c1_to_c26]]\n",
    "    for c in list_of_c1_to_c26:\n",
    "        data[c] = data[c]/gross_output\n",
    "        \n",
    "    data_original = data.copy()\n",
    "\n",
    "    for c in list_of_c1_to_c26:\n",
    "        data[c] = data[c] * temp_multiplier\n",
    "    # data_T.iloc[2031:2038,]  # .sum() does not have any effect here\n",
    "\n",
    "    I = np.identity(26)\n",
    "    # one_vector = np.ones(35)\n",
    "    one_vector = np.ones(26).reshape((26, 1))\n",
    "\n",
    "    # We use numpy.linalg.inv() function to calculate the inverse of a matrix.\n",
    "\n",
    "    temp = I - data\n",
    "    temp2 = np.linalg.inv(temp)\n",
    "    upstream_value = np.matmul(temp2,one_vector)\n",
    "    \n",
    "    temp_CE = I - data_original                   # CE = closed economy\n",
    "    temp2_CE = np.linalg.inv(temp_CE)\n",
    "    upstream_value_CE = np.matmul(temp2_CE,one_vector)\n",
    "    \n",
    "    return upstream_value, gross_output , upstream_value_CE\n",
    "\n",
    "def open_economy_UI_index_with_weighted_by_export(country_code,yyyy):\n",
    "    data_FD, data_Q, data_T,data_VA,data_QY , label_FD,label_Q,label_T,label_VA,country_codes, country_list,industry_codes_26,industry_codes_6 = load_dataset(yyyy)\n",
    "    # temp1 = data_T.copy()\n",
    "    data_T_for_X = data_T.copy()\n",
    "    # data_T_for_Y = data_T.copy()\n",
    "    temp2 = data_FD.copy()\n",
    "    # data_FD_for_Y = data_FD.copy()\n",
    "\n",
    "    row_level_one = country_codes.index(country_code)\n",
    "\n",
    "    data_T = data_T.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    \"\"\" multiplying by 26 as for a particular country the self IO table just needs the 26 rows starting from the row number \n",
    "    row_level_one * 26 because there are total 26 industries\"\"\"\n",
    "    temp_col_26 = np.arange(row_level_one*26, row_level_one*26 +26)\n",
    "    data_T = data_T[temp_col_26]\n",
    "    temp1= data_T.copy()\n",
    "\n",
    "    temp2 = temp2.iloc[row_level_one*26: row_level_one*26+26 , :]\n",
    "    temp_col_6 = np.arange(row_level_one*6 , row_level_one*6 +6)\n",
    "    temp2 = temp2[temp_col_6]\n",
    "\n",
    "    data = pd.concat([temp1, temp2] , axis = 1 , ignore_index= True )\n",
    "    data.columns = industry_codes_26 + industry_codes_6\n",
    "    c = data.columns\n",
    "    # #io_table[\"Total_use\"] = 0\n",
    "\n",
    "\n",
    "    # for c in c:\n",
    "    #     io_table[\"Total_use\"] = io_table[\"Total_use\"] + io_table[c]\n",
    "    # io_table\n",
    "\n",
    "    data[country_code] = industry_codes_26\n",
    "\n",
    "    cols = list(data.columns.values)\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    data = data[cols]\n",
    "\n",
    "\n",
    "    # renaming data columns\n",
    "\n",
    "    data = data.rename(columns={\"Agriculture\": \"c1\" ,\"Fishing\": \"c2\" , \"Mining and Quarrying\": \"c3\" ,\"Food & Beverages\": \"c4\" ,\n",
    "                               \"Textiles and Wearing Apparel\": \"c5\" ,\"Wood and Paper\": \"c6\" ,\n",
    "                                \"Petroleum, Chemical and Non-Metallic Mineral Products\": \"c7\" ,\"Metal Products\": \"c8\" ,\n",
    "                               \"Electrical and Machinery\": \"c9\" ,\"Transport Equipment\": \"c10\" , \"Other Manufacturing\": \"c11\" \n",
    "                                ,\"Recycling\": \"c12\" ,\n",
    "                               \"Electricity, Gas and Water\": \"c13\" ,\"Construction\": \"c14\" , \"Maintenance and Repair\": \"c15\" \n",
    "                                ,\"Wholesale Trade\": \"c16\" ,\n",
    "                               \"Retail Trade\" : \"c17\" , \"Hotels and Restraurants\": \"c18\" , \"Transport\": \"c19\" \n",
    "                                ,\"Post and Telecommunications\": \"c20\" ,\n",
    "                               \"Finacial Intermediation and Business Activities\": \"c21\" \n",
    "                                , \"Public Administration\": \"c22\" ,\"Education, Health and Other Services\": \"c23\" ,\n",
    "                               \"Private Households\": \"c24\" ,\"Others\": \"c25\" ,\"Re-export & Re-import\": \"c26\" })\n",
    "\n",
    "    data = data.rename(columns={\"Household final consumption P.3h\": \"f1\" ,\"Non-profit institutions serving households P.3n\": \"f2\" ,\n",
    "                                \"Government final consumption P.3g\": \"f3\" ,\"Gross fixed capital formation P.51\": \"f4\" ,\n",
    "                               \"Changes in inventories P.52\": \"f5\" ,\"Acquisitions less disposals of valuables P.53\": \"f6\"  })\n",
    "\n",
    "\n",
    "    list_of_c1_to_c26 = []\n",
    "    for i in range(1,27):\n",
    "      list_of_c1_to_c26.append(\"c\"+str(i))\n",
    "\n",
    "    list_of_f1_to_f6 = []\n",
    "    for i in range(1,7):\n",
    "      list_of_f1_to_f6.append(\"c\"+str(i))\n",
    "\n",
    "    # Import and export calculation\n",
    "\n",
    "    #IMPORT calculation\n",
    "\n",
    "    #temp1 = data_T\n",
    "    # temp_col_26\n",
    "\n",
    "    # data_T = data_T[temp_col_26]\n",
    "\n",
    "    temp_sum = []\n",
    "    total_sum_import_1 = []\n",
    "    for i in temp_col_26:\n",
    "        temp_sum.append(temp1[i].sum())\n",
    "        total_sum_import_1.append(data_T[i].sum())\n",
    "    #vertical addition   \n",
    "\n",
    "    # for i in temp_col_6:\n",
    "    #     total_sum_import_2.append(data_FD[i].sum())\n",
    "    #     print(i)\n",
    "\n",
    "    #Not including this as we only care if the data is corresponding to the industry level given a single country\n",
    "    # They are definitely importing something directing in the final demand section from different countries but not at \n",
    "    #      industry section level\n",
    "    # Though for the calculation of the export data both would be considered\n",
    "\n",
    "    temp_sum = np.asarray(temp_sum)\n",
    "    total_sum_import_1 = np.asarray(total_sum_import_1)\n",
    "\n",
    "    imports_sum = total_sum_import_1 - temp_sum\n",
    "#     print(\"\")\n",
    "#     print(imports_1)\n",
    "\n",
    "    # Exports - calculating exports\n",
    "\n",
    "    # temp2 = data_FD   4915 x 1140\n",
    "\n",
    "    data_T_for_X = data_T_for_X.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    data_T_for_X = data_T_for_X.drop(columns = [4914])\n",
    "    total_export_sum_1 = np.sum(data_T_for_X , axis=1).tolist()\n",
    "    total_export_sum_1 = np.asarray(total_export_sum_1)\n",
    "\n",
    "    temp_export_sum_1 = np.sum(temp1,axis=1).tolist()\n",
    "    temp_export_sum_1 = np.asarray(temp_export_sum_1)\n",
    "\n",
    "    export_sum_1 = total_export_sum_1 - temp_export_sum_1\n",
    "#     print(\"\")\n",
    "#     print(export_sum_1)\n",
    "\n",
    "\n",
    "    data_FD = data_FD.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    data_FD = data_FD.drop(columns = [1134,1135,1136,1137,1138,1139])\n",
    "    total_export_sum_2 = np.sum(data_FD , axis=1).tolist()         # 1134 columns\n",
    "    total_export_sum_2 = np.asarray(total_export_sum_2)\n",
    "\n",
    "    temp_export_sum_2 = np.sum(temp2,axis=1).tolist()            # 6 columns\n",
    "    temp_export_sum_2 = np.asarray(temp_export_sum_2)\n",
    "\n",
    "    export_sum_2 = total_export_sum_2 - temp_export_sum_2\n",
    "\n",
    "#     print(\"\")\n",
    "#     print(export_sum_2)\n",
    "\n",
    "    exports_sum = export_sum_1 + export_sum_2\n",
    "#     print(\"\")\n",
    "#     print(export_sum)\n",
    "\n",
    "\n",
    "    net_exports = exports_sum - imports_sum\n",
    "\n",
    "    # gross_output = data['Total_use']\n",
    "    # Calculating the gross output from the complete data\n",
    "    # We need one more set of data_T and data_FD\n",
    "\n",
    "    #data_T_row-wise total\n",
    "\n",
    "    # data_T_for_Y = data_T_for_Y.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    # data_T_for_Y = data_T_for_Y.drop(columns = [4914])\n",
    "    # gross_output_1 = np.sum(data_T_for_Y , axis=1).tolist()\n",
    "    # gross_output_1 = np.asarray(gross_output_1)\n",
    "\n",
    "    # data_FD_for_Y = data_FD_for_Y.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    # data_FD_for_Y = data_FD_for_Y.drop(columns = [1134,1135,1136,1137,1138,1139])\n",
    "    # gross_output_2 = np.sum(data_FD_for_Y , axis=1).tolist()         # 1134 columns\n",
    "    # gross_output_2 = np.asarray(gross_output_2)\n",
    "\n",
    "    gross_output = total_export_sum_1 + total_export_sum_2\n",
    "\n",
    "    temp_numerator = gross_output.copy()\n",
    "    temp_denominator = gross_output - net_exports\n",
    "    temp_multiplier = temp_numerator / temp_denominator\n",
    "\n",
    "    #Modifying the Dij values\n",
    "\n",
    "    data = data[[c for c in data.columns if c in list_of_c1_to_c26]]\n",
    "    for c in list_of_c1_to_c26:\n",
    "        data[c] = data[c]/gross_output\n",
    "        \n",
    "    data_original = data.copy()\n",
    "\n",
    "    for c in list_of_c1_to_c26:\n",
    "        data[c] = data[c] * temp_multiplier\n",
    "    # data_T.iloc[2031:2038,]  # .sum() does not have any effect here\n",
    "\n",
    "    I = np.identity(26)\n",
    "    # one_vector = np.ones(35)\n",
    "    one_vector = np.ones(26).reshape((26, 1))\n",
    "\n",
    "    # We use numpy.linalg.inv() function to calculate the inverse of a matrix.\n",
    "\n",
    "    temp = I - data\n",
    "    temp2 = np.linalg.inv(temp)\n",
    "    upstream_value = np.matmul(temp2,one_vector)\n",
    "    \n",
    "    upstream_value_transpose = upstream_value.reshape((1,26))\n",
    "    \n",
    "    \n",
    "#     gross_output_total = np.sum(gross_output)\n",
    "    exports_sum_total = np.sum(exports_sum)\n",
    "#     for i in range(row_level_one*26,row_level_one*26+26):\n",
    "#         gross_output_total = gross_output_total + gross_output[i]\n",
    "        \n",
    "#     temp_gross_output_weights = gross_output / gross_output_total\n",
    "    temp_exports_sum_weights = exports_sum/ exports_sum_total\n",
    "    print(exports_sum)\n",
    "    print(\"\")\n",
    "    print(exports_sum_total)\n",
    "    print(\"\")\n",
    "    print(temp_exports_sum_weights)\n",
    "    print(\"\")\n",
    "    print(upstream_value_transpose)\n",
    "    print(\"\")\n",
    "    \n",
    "    \n",
    "#     total_weight = 0\n",
    "#     for i in range(row_level_one*26,row_level_one*26+26):\n",
    "#         total_weight = total_weight + temp_gross_output_weights[i]\n",
    "\n",
    "#     print(\"\")\n",
    "#     print(\"Total weight is \", total_weight)\n",
    "\n",
    "#     a = np.matmul(upstream_value_transpose,temp_gross_output_weights)\n",
    "    a = np.matmul(upstream_value_transpose,temp_exports_sum_weights)\n",
    "    \n",
    "    temp_CE = I - data_original                   # CE = closed economy\n",
    "    temp2_CE = np.linalg.inv(temp_CE)\n",
    "    upstream_value_CE = np.matmul(temp2_CE,one_vector)\n",
    "    \n",
    "    upstream_value_CE_transpose = upstream_value_CE.reshape((1,26))\n",
    "#     gross_output_total = 0\n",
    "#     for i in range(row_level_one*26,row_level_one*26+26):\n",
    "#         gross_output_total = gross_output_total + gross_output[i]\n",
    "        \n",
    "#     temp_gross_output_weights = gross_output / gross_output_total\n",
    "    a_CE = np.matmul(upstream_value_CE_transpose,temp_exports_sum_weights)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return upstream_value, float(a), gross_output , upstream_value_CE,float(a_CE) , imports_sum , exports_sum\n",
    "\n",
    "def testing_code():\n",
    "    start = datetime.now()\n",
    "    commonwealth_countries = ['CHN']\n",
    "    start_year = 1990\n",
    "    end_year = 2015\n",
    "    \n",
    "    year_timeline = []\n",
    "    for i in range(start_year,end_year+1):\n",
    "        year_timeline.append(i)\n",
    "    print(year_timeline)\n",
    "\n",
    "    huha = pd.DataFrame(year_timeline)\n",
    "    huha_CE = pd.DataFrame(year_timeline)\n",
    "    \n",
    "    country_codes, country_list,industry_codes_26,industry_codes_6 , label_Q , label_VA = get_industry_code()\n",
    "#     upstream_value, gross_output , upstream_value_CE = open_economy_UI_index('AND',2010)\n",
    "\n",
    "    for c in commonwealth_countries:\n",
    "        print(\"\")\n",
    "        print(\"//////////////////////////////\")\n",
    "        print(\"the country in progress is \",c)\n",
    "        print(\"\")\n",
    "        temp_list = []\n",
    "        temp_list_CE = []\n",
    "\n",
    "    #     pd_gross_output = pd.DataFrame(industry_codes_26)\n",
    "        pd_imports = pd.DataFrame(industry_codes_26)\n",
    "        pd_exports = pd.DataFrame(industry_codes_26)\n",
    "        temp_UI = pd.DataFrame(industry_codes_26)\n",
    "        temp_UI_CE = pd.DataFrame(industry_codes_26)\n",
    "        #Rename the index 0 to the country code\n",
    "\n",
    "    #     pd_gross_output = pd_gross_output.rename(columns = {0 : c})\n",
    "        pd_imports = pd_imports.rename(columns = {0 : c})\n",
    "        pd_exports = pd_exports.rename(columns = {0 : c})\n",
    "        temp_UI = temp_UI.rename(columns = {0 : c})\n",
    "        temp_UI_CE = temp_UI_CE.rename(columns = {0 : c})\n",
    "\n",
    "\n",
    "\n",
    "        for yyyy in range(start_year,end_year+1):\n",
    "            print(\"the year is \", yyyy)\n",
    "            upstream_value,a, gross_output , upstream_value_CE,a_CE , imports_sum , exports_sum  = open_economy_UI_index_with_weighted_by_export(c,yyyy)\n",
    "    #         pd_gross_output[yyyy] = gross_output\n",
    "            pd_imports[yyyy] = imports_sum\n",
    "            pd_exports[yyyy] = exports_sum\n",
    "            temp_list.append(a)\n",
    "            temp_list_CE.append(a_CE)\n",
    "            temp_UI[yyyy] = upstream_value\n",
    "            temp_UI_CE[yyyy] = upstream_value_CE\n",
    "\n",
    "\n",
    "        huha[c] = temp_list\n",
    "        huha_CE[c] = temp_list_CE\n",
    "        print(\"The country completed is \", c)\n",
    "#         huha.to_csv(\"temp_so_far_\"+str(c)+\".csv\", index= False)\n",
    "#         huha_CE.to_csv(\"CE_temp_so_far_\"+ str(c)+\".csv\", index= False)\n",
    "    #     pd_gross_output.to_csv(str(c) + \"_gross_output.csv\", index = False)\n",
    "#         pd_imports.to_csv(\"Imports_\"+str(c) + \".csv\", index = False)\n",
    "#         pd_exports.to_csv(\"Exports_\"+str(c) + \".csv\", index = False)\n",
    "\n",
    "    #     temp_UI.to_csv(\"Open_Economy_\"+str(c) + \"_\" + \"upstream_value.csv\", index = False)\n",
    "    #     temp_UI_CE.to_csv(\"Closed_Economy_\"+str(c) + \"_\" + \"upstream_value.csv\", index = False)\n",
    "\n",
    "    end = datetime.now()\n",
    "#     huha.to_csv(\"Final_weighted_avg_UI_country_wise.csv\", index = False)\n",
    "#     huha_CE.to_csv(\"CE_Final_weighted_avg_UI_country_wise.csv\", index = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     print(upstream_value)\n",
    "    end = datetime.now()\n",
    "    print(end-start)\n",
    "    return huha,huha_CE , pd_imports, pd_exports\n",
    "\n",
    "def open_economy_UI_index_with_weighted_by_export_of43countries(country_code,yyyy,list_of_indices):\n",
    "    data_FD, data_Q, data_T,data_VA,data_QY , label_FD,label_Q,label_T,label_VA,country_codes, country_list,industry_codes_26,industry_codes_6 = load_dataset(yyyy)\n",
    "    # temp1 = data_T.copy()\n",
    "    data_T_for_X = data_T.copy()\n",
    "    # data_T_for_Y = data_T.copy()\n",
    "    temp2 = data_FD.copy()\n",
    "    # data_FD_for_Y = data_FD.copy()\n",
    "\n",
    "    row_level_one = country_codes.index(country_code)\n",
    "\n",
    "    data_T = data_T.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    \"\"\" multiplying by 26 as for a particular country the self IO table just needs the 26 rows starting from the row number \n",
    "    row_level_one * 26 because there are total 26 industries\"\"\"\n",
    "    temp_col_26 = np.arange(row_level_one*26, row_level_one*26 +26)\n",
    "    data_T = data_T[temp_col_26]\n",
    "    temp1= data_T.copy()\n",
    "\n",
    "    temp2 = temp2.iloc[row_level_one*26: row_level_one*26+26 , :]\n",
    "    temp_col_6 = np.arange(row_level_one*6 , row_level_one*6 +6)\n",
    "    temp2 = temp2[temp_col_6]\n",
    "\n",
    "    data = pd.concat([temp1, temp2] , axis = 1 , ignore_index= True )\n",
    "    data.columns = industry_codes_26 + industry_codes_6\n",
    "    c = data.columns\n",
    "    # #io_table[\"Total_use\"] = 0\n",
    "\n",
    "\n",
    "    # for c in c:\n",
    "    #     io_table[\"Total_use\"] = io_table[\"Total_use\"] + io_table[c]\n",
    "    # io_table\n",
    "\n",
    "    data[country_code] = industry_codes_26\n",
    "\n",
    "    cols = list(data.columns.values)\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    data = data[cols]\n",
    "\n",
    "\n",
    "    # renaming data columns\n",
    "\n",
    "    data = data.rename(columns={\"Agriculture\": \"c1\" ,\"Fishing\": \"c2\" , \"Mining and Quarrying\": \"c3\" ,\"Food & Beverages\": \"c4\" ,\n",
    "                               \"Textiles and Wearing Apparel\": \"c5\" ,\"Wood and Paper\": \"c6\" ,\n",
    "                                \"Petroleum, Chemical and Non-Metallic Mineral Products\": \"c7\" ,\"Metal Products\": \"c8\" ,\n",
    "                               \"Electrical and Machinery\": \"c9\" ,\"Transport Equipment\": \"c10\" , \"Other Manufacturing\": \"c11\" \n",
    "                                ,\"Recycling\": \"c12\" ,\n",
    "                               \"Electricity, Gas and Water\": \"c13\" ,\"Construction\": \"c14\" , \"Maintenance and Repair\": \"c15\" \n",
    "                                ,\"Wholesale Trade\": \"c16\" ,\n",
    "                               \"Retail Trade\" : \"c17\" , \"Hotels and Restraurants\": \"c18\" , \"Transport\": \"c19\" \n",
    "                                ,\"Post and Telecommunications\": \"c20\" ,\n",
    "                               \"Finacial Intermediation and Business Activities\": \"c21\" \n",
    "                                , \"Public Administration\": \"c22\" ,\"Education, Health and Other Services\": \"c23\" ,\n",
    "                               \"Private Households\": \"c24\" ,\"Others\": \"c25\" ,\"Re-export & Re-import\": \"c26\" })\n",
    "\n",
    "    data = data.rename(columns={\"Household final consumption P.3h\": \"f1\" ,\"Non-profit institutions serving households P.3n\": \"f2\" ,\n",
    "                                \"Government final consumption P.3g\": \"f3\" ,\"Gross fixed capital formation P.51\": \"f4\" ,\n",
    "                               \"Changes in inventories P.52\": \"f5\" ,\"Acquisitions less disposals of valuables P.53\": \"f6\"  })\n",
    "\n",
    "\n",
    "    list_of_c1_to_c26 = []\n",
    "    for i in range(1,27):\n",
    "      list_of_c1_to_c26.append(\"c\"+str(i))\n",
    "\n",
    "    list_of_f1_to_f6 = []\n",
    "    for i in range(1,7):\n",
    "      list_of_f1_to_f6.append(\"c\"+str(i))\n",
    "\n",
    "    # Import and export calculation\n",
    "\n",
    "    #IMPORT calculation\n",
    "\n",
    "    #temp1 = data_T\n",
    "    # temp_col_26\n",
    "\n",
    "    # data_T = data_T[temp_col_26]\n",
    "\n",
    "    temp_sum = []\n",
    "    total_sum_import_1 = []\n",
    "    for i in temp_col_26:\n",
    "        temp_sum.append(temp1[i].sum())\n",
    "        total_sum_import_1.append(data_T[i].sum())\n",
    "    #vertical addition   \n",
    "\n",
    "    # for i in temp_col_6:\n",
    "    #     total_sum_import_2.append(data_FD[i].sum())\n",
    "    #     print(i)\n",
    "\n",
    "    #Not including this as we only care if the data is corresponding to the industry level given a single country\n",
    "    # They are definitely importing something directing in the final demand section from different countries but not at \n",
    "    #      industry section level\n",
    "    # Though for the calculation of the export data both would be considered\n",
    "\n",
    "    temp_sum = np.asarray(temp_sum)\n",
    "    total_sum_import_1 = np.asarray(total_sum_import_1)\n",
    "\n",
    "    imports_sum = total_sum_import_1 - temp_sum\n",
    "#     print(\"\")\n",
    "#     print(imports_1)\n",
    "\n",
    "    # Exports - calculating exports\n",
    "\n",
    "    # temp2 = data_FD   4915 x 1140\n",
    "\n",
    "    data_T_for_X = data_T_for_X.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    data_T_for_X = data_T_for_X.drop(columns = [4914])\n",
    "    total_export_sum_1 = np.sum(data_T_for_X , axis=1).tolist()\n",
    "    total_export_sum_1 = np.asarray(total_export_sum_1)\n",
    "\n",
    "    temp_export_sum_1 = np.sum(temp1,axis=1).tolist()\n",
    "    temp_export_sum_1 = np.asarray(temp_export_sum_1)\n",
    "\n",
    "    export_sum_1 = total_export_sum_1 - temp_export_sum_1\n",
    "#     print(\"\")\n",
    "#     print(export_sum_1)\n",
    "\n",
    "\n",
    "    data_FD = data_FD.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    data_FD = data_FD.drop(columns = [1134,1135,1136,1137,1138,1139])\n",
    "    total_export_sum_2 = np.sum(data_FD , axis=1).tolist()         # 1134 columns\n",
    "    total_export_sum_2 = np.asarray(total_export_sum_2)\n",
    "\n",
    "    temp_export_sum_2 = np.sum(temp2,axis=1).tolist()            # 6 columns\n",
    "    temp_export_sum_2 = np.asarray(temp_export_sum_2)\n",
    "\n",
    "    export_sum_2 = total_export_sum_2 - temp_export_sum_2\n",
    "\n",
    "#     print(\"\")\n",
    "#     print(export_sum_2)\n",
    "\n",
    "    exports_sum = export_sum_1 + export_sum_2\n",
    "#     print(\"\")\n",
    "#     print(export_sum)\n",
    "\n",
    "\n",
    "    net_exports = exports_sum - imports_sum\n",
    "\n",
    "    # gross_output = data['Total_use']\n",
    "    # Calculating the gross output from the complete data\n",
    "    # We need one more set of data_T and data_FD\n",
    "\n",
    "    #data_T_row-wise total\n",
    "\n",
    "    # data_T_for_Y = data_T_for_Y.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    # data_T_for_Y = data_T_for_Y.drop(columns = [4914])\n",
    "    # gross_output_1 = np.sum(data_T_for_Y , axis=1).tolist()\n",
    "    # gross_output_1 = np.asarray(gross_output_1)\n",
    "\n",
    "    # data_FD_for_Y = data_FD_for_Y.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    # data_FD_for_Y = data_FD_for_Y.drop(columns = [1134,1135,1136,1137,1138,1139])\n",
    "    # gross_output_2 = np.sum(data_FD_for_Y , axis=1).tolist()         # 1134 columns\n",
    "    # gross_output_2 = np.asarray(gross_output_2)\n",
    "\n",
    "    gross_output = total_export_sum_1 + total_export_sum_2\n",
    "\n",
    "    temp_numerator = gross_output.copy()\n",
    "    temp_denominator = gross_output - net_exports\n",
    "    temp_multiplier = temp_numerator / temp_denominator\n",
    "\n",
    "    #Modifying the Dij values\n",
    "\n",
    "    data = data[[c for c in data.columns if c in list_of_c1_to_c26]]\n",
    "    for c in list_of_c1_to_c26:\n",
    "        data[c] = data[c]/gross_output\n",
    "        \n",
    "    data_original = data.copy()\n",
    "\n",
    "    for c in list_of_c1_to_c26:\n",
    "        data[c] = data[c] * temp_multiplier\n",
    "    # data_T.iloc[2031:2038,]  # .sum() does not have any effect here\n",
    "\n",
    "    I = np.identity(26)\n",
    "    # one_vector = np.ones(35)\n",
    "    one_vector = np.ones(26).reshape((26, 1))\n",
    "\n",
    "    # We use numpy.linalg.inv() function to calculate the inverse of a matrix.\n",
    "\n",
    "    temp = I - data\n",
    "    temp2 = np.linalg.inv(temp)\n",
    "    upstream_value = np.matmul(temp2,one_vector)\n",
    "    \n",
    "    upstream_value_transpose = upstream_value.reshape((1,26))\n",
    "    \n",
    "    \n",
    "#     gross_output_total = np.sum(gross_output)\n",
    "    exports_sum_total = np.sum(exports_sum)\n",
    "#     for i in range(row_level_one*26,row_level_one*26+26):\n",
    "#         gross_output_total = gross_output_total + gross_output[i]\n",
    "        \n",
    "#     temp_gross_output_weights = gross_output / gross_output_total\n",
    "    temp_exports_sum_weights = exports_sum/ exports_sum_total\n",
    "    \n",
    "#     total_weight = 0\n",
    "#     for i in range(row_level_one*26,row_level_one*26+26):\n",
    "#         total_weight = total_weight + temp_gross_output_weights[i]\n",
    "\n",
    "#     print(\"\")\n",
    "#     print(\"Total weight is \", total_weight)\n",
    "\n",
    "#     a = np.matmul(upstream_value_transpose,temp_gross_output_weights)\n",
    "    a = np.matmul(upstream_value_transpose,temp_exports_sum_weights)\n",
    "    \n",
    "    temp_CE = I - data_original                   # CE = closed economy\n",
    "    temp2_CE = np.linalg.inv(temp_CE)\n",
    "    upstream_value_CE = np.matmul(temp2_CE,one_vector)\n",
    "    \n",
    "    upstream_value_CE_transpose = upstream_value_CE.reshape((1,26))\n",
    "#     gross_output_total = 0\n",
    "#     for i in range(row_level_one*26,row_level_one*26+26):\n",
    "#         gross_output_total = gross_output_total + gross_output[i]\n",
    "        \n",
    "#     temp_gross_output_weights = gross_output / gross_output_total\n",
    "    a_CE = np.matmul(upstream_value_CE_transpose,temp_exports_sum_weights)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return upstream_value, float(a), gross_output , upstream_value_CE,float(a_CE) , imports_sum , exports_sum\n",
    "\n",
    "\n",
    "# from datetime import datetime\n",
    "# commonwealth_countries = ['ATG' , 'AUS' , 'BHS' , 'BGD' , 'BRB' , 'BLZ' , 'BWA' , 'BRN' , 'CMR' , 'CAN' , 'CYP' , 'DOM' , 'FJI' , 'GMB' , 'GHA' , 'GUY' , 'IND' , 'JAM' , 'KEN' , 'LSO' , 'MWI' , 'MYS' , 'MLT' , 'MUS' , 'MOZ' , 'NAM' , 'NZL' , 'NGA' , 'PAK' , 'PNG' , 'RWA' , 'WSM' , 'SYC' , 'SLE' , 'SGP' , 'ZAF' , 'LKA' , 'SWZ' , 'TTO' , 'UGA' , 'GBR' , 'VUT' , 'ZMB']\n",
    "# # commonwealth_countries = ['AUS']\n",
    "# start = datetime.now()\n",
    "# start_year = 1990\n",
    "# end_year = 2015\n",
    "\n",
    "# year_timeline = []\n",
    "# for i in range(start_year,end_year+1):\n",
    "#     year_timeline.append(i)\n",
    "# print(year_timeline)\n",
    "\n",
    "# huha = pd.DataFrame(year_timeline)\n",
    "# huha_CE = pd.DataFrame(year_timeline)\n",
    "\n",
    "# #get industry codes 26\n",
    "# country_codes, country_list,industry_codes_26,industry_codes_6 , label_Q , label_VA = get_industry_code()\n",
    "\n",
    "# for c in commonwealth_countries:\n",
    "#     print(\"\")\n",
    "#     print(\"//////////////////////////////\")\n",
    "#     print(\"the country in progress is \",c)\n",
    "#     print(\"\")\n",
    "#     temp_list = []\n",
    "#     temp_list_CE = []\n",
    "    \n",
    "# #     pd_gross_output = pd.DataFrame(industry_codes_26)\n",
    "#     pd_imports = pd.DataFrame(industry_codes_26)\n",
    "#     pd_exports = pd.DataFrame(industry_codes_26)\n",
    "#     temp_UI = pd.DataFrame(industry_codes_26)\n",
    "#     temp_UI_CE = pd.DataFrame(industry_codes_26)\n",
    "#     #Rename the index 0 to the country code\n",
    "    \n",
    "# #     pd_gross_output = pd_gross_output.rename(columns = {0 : c})\n",
    "#     pd_imports = pd_imports.rename(columns = {0 : c})\n",
    "#     pd_exports = pd_exports.rename(columns = {0 : c})\n",
    "#     temp_UI = temp_UI.rename(columns = {0 : c})\n",
    "#     temp_UI_CE = temp_UI_CE.rename(columns = {0 : c})\n",
    "    \n",
    "    \n",
    "    \n",
    "#     for yyyy in range(start_year,end_year+1):\n",
    "#         print(\"the year is \", yyyy)\n",
    "#         upstream_value, a, gross_output , upstream_value_CE,a_CE , imports_sum , exports_sum  = open_economy_UI_index_with_weighted_by_export(c,yyyy)\n",
    "# #         pd_gross_output[yyyy] = gross_output\n",
    "#         pd_imports[yyyy] = imports_sum\n",
    "#         pd_exports[yyyy] = exports_sum\n",
    "#         temp_list.append(a)\n",
    "#         temp_list_CE.append(a_CE)\n",
    "#         temp_UI[yyyy] = upstream_value\n",
    "#         temp_UI_CE[yyyy] = upstream_value_CE\n",
    "        \n",
    "\n",
    "#     huha[c] = temp_list\n",
    "#     huha_CE[c] = temp_list_CE\n",
    "#     print(\"The country completed is \", c)\n",
    "#     huha.to_csv(\"temp_so_far_\"+str(c)+\".csv\", index= False)\n",
    "#     huha_CE.to_csv(\"CE_temp_so_far_\"+ str(c)+\".csv\", index= False)\n",
    "# #     pd_gross_output.to_csv(str(c) + \"_gross_output.csv\", index = False)\n",
    "#     pd_imports.to_csv(\"Imports_\"+str(c) + \".csv\", index = False)\n",
    "#     pd_exports.to_csv(\"Exports_\"+str(c) + \".csv\", index = False)\n",
    "    \n",
    "# #     temp_UI.to_csv(\"Open_Economy_\"+str(c) + \"_\" + \"upstream_value.csv\", index = False)\n",
    "# #     temp_UI_CE.to_csv(\"Closed_Economy_\"+str(c) + \"_\" + \"upstream_value.csv\", index = False)\n",
    "\n",
    "# end = datetime.now()\n",
    "# huha.to_csv(\"Final_weighted_avg_UI_country_wise.csv\", index = False)\n",
    "# huha_CE.to_csv(\"CE_Final_weighted_avg_UI_country_wise.csv\", index = False)\n",
    "# print(\"the time taken is \", end-start)\n",
    "\n",
    "def get_UI_index(country_code,yyyy):\n",
    "    data_FD, data_Q, data_T,data_VA,data_QY , label_FD,label_Q,label_T,label_VA,country_codes, country_list,industry_codes_26,industry_codes_6 = load_dataset(yyyy)\n",
    "    # temp1 = data_T.copy()\n",
    "    data_T_for_X = data_T.copy()\n",
    "    # data_T_for_Y = data_T.copy()\n",
    "    temp2 = data_FD.copy()\n",
    "    # data_FD_for_Y = data_FD.copy()\n",
    "\n",
    "    row_level_one = country_codes.index(country_code)\n",
    "\n",
    "    data_T = data_T.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    \"\"\" multiplying by 26 as for a particular country the self IO table just needs the 26 rows starting from the row number \n",
    "    row_level_one * 26 because there are total 26 industries\"\"\"\n",
    "    temp_col_26 = np.arange(row_level_one*26, row_level_one*26 +26)\n",
    "    data_T = data_T[temp_col_26]\n",
    "    temp1= data_T.copy()\n",
    "\n",
    "    temp2 = temp2.iloc[row_level_one*26: row_level_one*26+26 , :]\n",
    "    temp_col_6 = np.arange(row_level_one*6 , row_level_one*6 +6)\n",
    "    temp2 = temp2[temp_col_6]\n",
    "\n",
    "    data = pd.concat([temp1, temp2] , axis = 1 , ignore_index= True )\n",
    "    data.columns = industry_codes_26 + industry_codes_6\n",
    "    c = data.columns\n",
    "    # #io_table[\"Total_use\"] = 0\n",
    "\n",
    "\n",
    "    # for c in c:\n",
    "    #     io_table[\"Total_use\"] = io_table[\"Total_use\"] + io_table[c]\n",
    "    # io_table\n",
    "\n",
    "    data[country_code] = industry_codes_26\n",
    "\n",
    "    cols = list(data.columns.values)\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    data = data[cols]\n",
    "\n",
    "\n",
    "    # renaming data columns\n",
    "\n",
    "    data = data.rename(columns={\"Agriculture\": \"c1\" ,\"Fishing\": \"c2\" , \"Mining and Quarrying\": \"c3\" ,\"Food & Beverages\": \"c4\" ,\n",
    "                               \"Textiles and Wearing Apparel\": \"c5\" ,\"Wood and Paper\": \"c6\" ,\n",
    "                                \"Petroleum, Chemical and Non-Metallic Mineral Products\": \"c7\" ,\"Metal Products\": \"c8\" ,\n",
    "                               \"Electrical and Machinery\": \"c9\" ,\"Transport Equipment\": \"c10\" , \"Other Manufacturing\": \"c11\" \n",
    "                                ,\"Recycling\": \"c12\" ,\n",
    "                               \"Electricity, Gas and Water\": \"c13\" ,\"Construction\": \"c14\" , \"Maintenance and Repair\": \"c15\" \n",
    "                                ,\"Wholesale Trade\": \"c16\" ,\n",
    "                               \"Retail Trade\" : \"c17\" , \"Hotels and Restraurants\": \"c18\" , \"Transport\": \"c19\" \n",
    "                                ,\"Post and Telecommunications\": \"c20\" ,\n",
    "                               \"Finacial Intermediation and Business Activities\": \"c21\" \n",
    "                                , \"Public Administration\": \"c22\" ,\"Education, Health and Other Services\": \"c23\" ,\n",
    "                               \"Private Households\": \"c24\" ,\"Others\": \"c25\" ,\"Re-export & Re-import\": \"c26\" })\n",
    "\n",
    "    data = data.rename(columns={\"Household final consumption P.3h\": \"f1\" ,\"Non-profit institutions serving households P.3n\": \"f2\" ,\n",
    "                                \"Government final consumption P.3g\": \"f3\" ,\"Gross fixed capital formation P.51\": \"f4\" ,\n",
    "                               \"Changes in inventories P.52\": \"f5\" ,\"Acquisitions less disposals of valuables P.53\": \"f6\"  })\n",
    "\n",
    "\n",
    "    list_of_c1_to_c26 = []\n",
    "    for i in range(1,27):\n",
    "      list_of_c1_to_c26.append(\"c\"+str(i))\n",
    "\n",
    "    list_of_f1_to_f6 = []\n",
    "    for i in range(1,7):\n",
    "      list_of_f1_to_f6.append(\"c\"+str(i))\n",
    "\n",
    "    # Import and export calculation\n",
    "\n",
    "    #IMPORT calculation\n",
    "\n",
    "    #temp1 = data_T\n",
    "    # temp_col_26\n",
    "\n",
    "    # data_T = data_T[temp_col_26]\n",
    "\n",
    "    temp_sum = []\n",
    "    total_sum_import_1 = []\n",
    "    for i in temp_col_26:\n",
    "        temp_sum.append(temp1[i].sum())\n",
    "        total_sum_import_1.append(data_T[i].sum())\n",
    "    #vertical addition   \n",
    "\n",
    "    # for i in temp_col_6:\n",
    "    #     total_sum_import_2.append(data_FD[i].sum())\n",
    "    #     print(i)\n",
    "\n",
    "    #Not including this as we only care if the data is corresponding to the industry level given a single country\n",
    "    # They are definitely importing something directing in the final demand section from different countries but not at \n",
    "    #      industry section level\n",
    "    # Though for the calculation of the export data both would be considered\n",
    "\n",
    "    temp_sum = np.asarray(temp_sum)\n",
    "    total_sum_import_1 = np.asarray(total_sum_import_1)\n",
    "\n",
    "    imports_sum = total_sum_import_1 - temp_sum\n",
    "#     print(\"\")\n",
    "#     print(imports_1)\n",
    "\n",
    "    # Exports - calculating exports\n",
    "\n",
    "    # temp2 = data_FD   4915 x 1140\n",
    "\n",
    "    data_T_for_X = data_T_for_X.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    data_T_for_X = data_T_for_X.drop(columns = [4914])\n",
    "    total_export_sum_1 = np.sum(data_T_for_X , axis=1).tolist()\n",
    "    total_export_sum_1 = np.asarray(total_export_sum_1)\n",
    "\n",
    "    temp_export_sum_1 = np.sum(temp1,axis=1).tolist()\n",
    "    temp_export_sum_1 = np.asarray(temp_export_sum_1)\n",
    "\n",
    "    export_sum_1 = total_export_sum_1 - temp_export_sum_1\n",
    "#     print(\"\")\n",
    "#     print(export_sum_1)\n",
    "\n",
    "\n",
    "    data_FD = data_FD.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    data_FD = data_FD.drop(columns = [1134,1135,1136,1137,1138,1139])\n",
    "    total_export_sum_2 = np.sum(data_FD , axis=1).tolist()         # 1134 columns\n",
    "    total_export_sum_2 = np.asarray(total_export_sum_2)\n",
    "\n",
    "    temp_export_sum_2 = np.sum(temp2,axis=1).tolist()            # 6 columns\n",
    "    temp_export_sum_2 = np.asarray(temp_export_sum_2)\n",
    "\n",
    "    export_sum_2 = total_export_sum_2 - temp_export_sum_2\n",
    "\n",
    "#     print(\"\")\n",
    "#     print(export_sum_2)\n",
    "\n",
    "    exports_sum = export_sum_1 + export_sum_2\n",
    "#     print(\"\")\n",
    "#     print(export_sum)\n",
    "\n",
    "\n",
    "    net_exports = exports_sum - imports_sum\n",
    "\n",
    "    # gross_output = data['Total_use']\n",
    "    # Calculating the gross output from the complete data\n",
    "    # We need one more set of data_T and data_FD\n",
    "\n",
    "    #data_T_row-wise total\n",
    "\n",
    "    # data_T_for_Y = data_T_for_Y.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    # data_T_for_Y = data_T_for_Y.drop(columns = [4914])\n",
    "    # gross_output_1 = np.sum(data_T_for_Y , axis=1).tolist()\n",
    "    # gross_output_1 = np.asarray(gross_output_1)\n",
    "\n",
    "    # data_FD_for_Y = data_FD_for_Y.iloc[row_level_one * 26: row_level_one *26 +26 , :]\n",
    "    # data_FD_for_Y = data_FD_for_Y.drop(columns = [1134,1135,1136,1137,1138,1139])\n",
    "    # gross_output_2 = np.sum(data_FD_for_Y , axis=1).tolist()         # 1134 columns\n",
    "    # gross_output_2 = np.asarray(gross_output_2)\n",
    "\n",
    "    gross_output = total_export_sum_1 + total_export_sum_2\n",
    "\n",
    "    temp_numerator = gross_output.copy()\n",
    "    temp_denominator = gross_output - net_exports\n",
    "    temp_multiplier = temp_numerator / temp_denominator\n",
    "\n",
    "    #Modifying the Dij values\n",
    "\n",
    "    data = data[[c for c in data.columns if c in list_of_c1_to_c26]]\n",
    "    for c in list_of_c1_to_c26:\n",
    "        data[c] = data[c]/gross_output\n",
    "        \n",
    "    data_original = data.copy()\n",
    "\n",
    "    for c in list_of_c1_to_c26:\n",
    "        data[c] = data[c] * temp_multiplier\n",
    "    # data_T.iloc[2031:2038,]  # .sum() does not have any effect here\n",
    "\n",
    "    I = np.identity(26)\n",
    "    # one_vector = np.ones(35)\n",
    "    one_vector = np.ones(26).reshape((26, 1))\n",
    "\n",
    "    # We use numpy.linalg.inv() function to calculate the inverse of a matrix.\n",
    "\n",
    "    temp = I - data\n",
    "    temp2 = np.linalg.inv(temp)\n",
    "    upstream_value = np.matmul(temp2,one_vector)\n",
    "    \n",
    "    upstream_value_transpose = upstream_value.reshape((1,26))\n",
    "    \n",
    "    \n",
    "#     gross_output_total = np.sum(gross_output)\n",
    "    exports_sum_total = np.sum(exports_sum)\n",
    "#     for i in range(row_level_one*26,row_level_one*26+26):\n",
    "#         gross_output_total = gross_output_total + gross_output[i]\n",
    "        \n",
    "#     temp_gross_output_weights = gross_output / gross_output_total\n",
    "    temp_exports_sum_weights = exports_sum/ exports_sum_total\n",
    "    \n",
    "#     total_weight = 0\n",
    "#     for i in range(row_level_one*26,row_level_one*26+26):\n",
    "#         total_weight = total_weight + temp_gross_output_weights[i]\n",
    "\n",
    "#     print(\"\")\n",
    "#     print(\"Total weight is \", total_weight)\n",
    "\n",
    "#     a = np.matmul(upstream_value_transpose,temp_gross_output_weights)\n",
    "    a = np.matmul(upstream_value_transpose,temp_exports_sum_weights)\n",
    "    \n",
    "    temp_CE = I - data_original                   # CE = closed economy\n",
    "    temp2_CE = np.linalg.inv(temp_CE)\n",
    "    upstream_value_CE = np.matmul(temp2_CE,one_vector)\n",
    "    \n",
    "    upstream_value_CE_transpose = upstream_value_CE.reshape((1,26))\n",
    "#     gross_output_total = 0\n",
    "#     for i in range(row_level_one*26,row_level_one*26+26):\n",
    "#         gross_output_total = gross_output_total + gross_output[i]\n",
    "        \n",
    "#     temp_gross_output_weights = gross_output / gross_output_total\n",
    "    a_CE = np.matmul(upstream_value_CE_transpose,temp_exports_sum_weights)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return upstream_value\n",
    "\n",
    "\n",
    "def get_weighted_UI(commonwealth_countries,start_year,end_year):\n",
    "    start = datetime.now()\n",
    "    \n",
    "    year_timeline = []\n",
    "    for i in range(start_year,end_year+1):\n",
    "        year_timeline.append(i)\n",
    "    print(year_timeline)\n",
    "\n",
    "    huha = pd.DataFrame(year_timeline)\n",
    "    huha_CE = pd.DataFrame(year_timeline)\n",
    "    \n",
    "    country_codes, country_list,industry_codes_26,industry_codes_6 , label_Q , label_VA = get_industry_code()\n",
    "#     upstream_value, gross_output , upstream_value_CE = open_economy_UI_index('AND',2010)\n",
    "\n",
    "    for c in commonwealth_countries:\n",
    "        print(\"\")\n",
    "        print(\"//////////////////////////////\")\n",
    "        print(\"the country in progress is \",c)\n",
    "        print(\"\")\n",
    "        temp_list = []\n",
    "        temp_list_CE = []\n",
    "\n",
    "    #     pd_gross_output = pd.DataFrame(industry_codes_26)\n",
    "        pd_imports = pd.DataFrame(industry_codes_26)\n",
    "        pd_exports = pd.DataFrame(industry_codes_26)\n",
    "        temp_UI = pd.DataFrame(industry_codes_26)\n",
    "        temp_UI_CE = pd.DataFrame(industry_codes_26)\n",
    "        #Rename the index 0 to the country code\n",
    "\n",
    "    #     pd_gross_output = pd_gross_output.rename(columns = {0 : c})\n",
    "        pd_imports = pd_imports.rename(columns = {0 : c})\n",
    "        pd_exports = pd_exports.rename(columns = {0 : c})\n",
    "        temp_UI = temp_UI.rename(columns = {0 : c})\n",
    "        temp_UI_CE = temp_UI_CE.rename(columns = {0 : c})\n",
    "\n",
    "\n",
    "\n",
    "        for yyyy in range(start_year,end_year+1):\n",
    "            print(\"the year is \", yyyy)\n",
    "            upstream_value,a, gross_output , upstream_value_CE,a_CE , imports_sum , exports_sum  = open_economy_UI_index_with_weighted_by_export(c,yyyy)\n",
    "    #         pd_gross_output[yyyy] = gross_output\n",
    "            pd_imports[yyyy] = imports_sum\n",
    "            pd_exports[yyyy] = exports_sum\n",
    "            temp_list.append(a)\n",
    "            temp_list_CE.append(a_CE)\n",
    "            temp_UI[yyyy] = upstream_value\n",
    "            temp_UI_CE[yyyy] = upstream_value_CE\n",
    "\n",
    "\n",
    "        huha[c] = temp_list\n",
    "        huha_CE[c] = temp_list_CE\n",
    "        print(\"The country completed is \", c)\n",
    "#         huha.to_csv(\"temp_so_far_\"+str(c)+\".csv\", index= False)\n",
    "#         huha_CE.to_csv(\"CE_temp_so_far_\"+ str(c)+\".csv\", index= False)\n",
    "    #     pd_gross_output.to_csv(str(c) + \"_gross_output.csv\", index = False)\n",
    "#         pd_imports.to_csv(\"Imports_\"+str(c) + \".csv\", index = False)\n",
    "#         pd_exports.to_csv(\"Exports_\"+str(c) + \".csv\", index = False)\n",
    "\n",
    "    #     temp_UI.to_csv(\"Open_Economy_\"+str(c) + \"_\" + \"upstream_value.csv\", index = False)\n",
    "    #     temp_UI_CE.to_csv(\"Closed_Economy_\"+str(c) + \"_\" + \"upstream_value.csv\", index = False)\n",
    "\n",
    "    end = datetime.now()\n",
    "#     huha.to_csv(\"Final_weighted_avg_UI_country_wise.csv\", index = False)\n",
    "#     huha_CE.to_csv(\"CE_Final_weighted_avg_UI_country_wise.csv\", index = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     print(upstream_value)\n",
    "    end = datetime.now()\n",
    "    print(\"The time taken is as follows:\")\n",
    "    print(end-start)\n",
    "    \n",
    "    return huha\n",
    "# # country_list\n",
    "# country_code_and_list = pd.DataFrame(country_list)\n",
    "# country_code_and_list[1] = country_codes\n",
    "# country_code_and_list.to_csv(\"country_code_and_list.csv\", index = False)\n",
    "\n",
    "country_codes, country_list,industry_codes_26,industry_codes_6 , label_Q , label_VA = get_industry_code()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Parameters\n",
    "\n",
    "ncntry  = 189\n",
    "nsec    = 26\n",
    "nfd     = 6\n",
    "\n",
    "# %% EORA Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GO_c = np.sum(np.multiply(np.matlib.repmat(np.asarray(GO_cs), 1, ncntry),imtx_cs_c) ,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.matlib.repmat(GO_cs, 1, ncntry).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "country = 'IND'\n",
    "yyyy = 2008\n",
    "data_FD, data_Q, data_T,data_VA,data_QY , label_FD,label_Q,label_T,label_VA,country_codes, country_list,industry_codes_26,industry_codes_6 = load_dataset(yyyy)\n",
    "\n",
    "FD = np.sum(np.reshape(data_FD.values,(ncntry*nsec+1, nfd,-1), order='F'),axis=1)        # 1140 columns\n",
    "FD = pd.DataFrame(FD)\n",
    "\n",
    "va_total_cs = np.sum(data_VA , axis =0)\n",
    "va_total_cs = np.asarray(va_total_cs)\n",
    "\n",
    "#Intermediate Demand\n",
    "GRTR_INT_cs_cs = data_T.iloc[0:ncntry*nsec,0:ncntry*nsec]\n",
    "#Final Demand\n",
    "GRTR_FNL_cs_c = FD.iloc[0:ncntry*nsec,0:ncntry]\n",
    "#Value added\n",
    "VALU_cs = va_total_cs[0:ncntry*nsec]\n",
    "\n",
    "\n",
    "#  (B) Identity matrices for summing across sectors (when calculating totals by country)\n",
    "\n",
    "imtx_cs_c= np.ones((nsec,1))\n",
    "ivector=np.ones((nsec,1))\n",
    "for i in range(0,ncntry -1):\n",
    "    imtx_cs_c = scipy.linalg.block_diag(imtx_cs_c, ivector)\n",
    "imtx_cs_c = pd.DataFrame(imtx_cs_c)\n",
    "    \n",
    "imtx_cs_cs= np.ones((nsec,nsec))\n",
    "ivector=np.ones((nsec,nsec))\n",
    "for i in range(0,ncntry -1):\n",
    "    imtx_cs_cs = scipy.linalg.block_diag(imtx_cs_cs, ivector)\n",
    "imtx_cs_cs = pd.DataFrame(imtx_cs_cs)\n",
    "\n",
    "\n",
    "imtx_c_cs= np.ones((1,nsec))\n",
    "ivector = np.ones((1,nsec))\n",
    "for i in range(0,ncntry -1):\n",
    "    imtx_c_cs = scipy.linalg.block_diag(imtx_c_cs, ivector)\n",
    "imtx_c_cs = pd.DataFrame(imtx_c_cs)\n",
    "\n",
    "\n",
    "imtx_c_c= np.eye(ncntry)\n",
    "imtx_c_c = pd.DataFrame(imtx_c_c)\n",
    "\n",
    "imtx_cs_ck= np.ones((nsec,nfd))\n",
    "ivector=np.ones((nsec,nfd))\n",
    "for i in range(0,ncntry -1):\n",
    "    imtx_cs_ck = scipy.linalg.block_diag(imtx_cs_ck, ivector)\n",
    "imtx_cs_ck = pd.DataFrame(imtx_cs_ck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  (C) Calculating Gross Ouput (GO)\n",
    "\n",
    "# Without statistical discrepancy\n",
    "\n",
    "GO_INT_part = np.sum(np.reshape(GRTR_INT_cs_cs.values,(ncntry*nsec, nsec,-1), order='F'), axis=1)\n",
    "GO_INT_part = pd.DataFrame(GO_INT_part)\n",
    "\n",
    "GO_cs_c = GO_INT_part + GRTR_FNL_cs_c\n",
    "GO_cs = np.sum(GO_cs_c,axis=1)\n",
    "GO_cs = np.asarray(GO_cs).reshape(4914,1)\n",
    "\n",
    "################################\n",
    "GGO_INT_part = np.sum(GRTR_INT_cs_cs, axis =0)\n",
    "GGO_cs = GGO_INT_part + VALU_cs\n",
    "GGO_cs = np.asarray(GGO_cs).reshape(4914,1)\n",
    "###############################\n",
    "\n",
    "GO_c_c = np.dot(imtx_c_cs,GO_cs_c)\n",
    "GO_c = np.sum(np.multiply(np.matlib.repmat(GO_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "\n",
    "VALU_cs = np.asarray(VALU_cs).reshape(4914,1)\n",
    "VALU_c = np.sum(np.multiply(np.matlib.repmat(VALU_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "\n",
    "Inputs_cs = np.sum(GRTR_INT_cs_cs,axis=0)\n",
    "Inputs_cs = np.asarray(Inputs_cs).reshape(4914,1)\n",
    "Inputs_c = np.sum(np.multiply(np.matlib.repmat(Inputs_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "VALU_derived_cs = GO_cs - Inputs_cs\n",
    "VALU_derived_cs = np.asarray(VALU_derived_cs).reshape(4914,1)\n",
    "\n",
    "VALU_derived_c = np.sum(np.multiply(np.matlib.repmat(VALU_derived_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "\n",
    "\n",
    "# (E) Gross Exports\n",
    "#  Gross exports of intermediate goods and services from domestic\n",
    "#  sector s in country c\n",
    "\n",
    "EXGR_INT_cs_cs = np.multiply(GRTR_INT_cs_cs,(np.ones((ncntry*nsec,ncntry*nsec)) - imtx_cs_cs))\n",
    "\n",
    "EXGR_INT_cs_c = np.sum(np.reshape(EXGR_INT_cs_cs.values,(ncntry*nsec, nsec,-1), order='F'), axis=1)\n",
    "EXGR_INT_cs_c = pd.DataFrame(EXGR_INT_cs_c)\n",
    "\n",
    "\n",
    "EXGR_INT_cs = np.sum(EXGR_INT_cs_c,axis = 1)\n",
    "temp_EXGR_INT_cs = EXGR_INT_cs.copy()\n",
    "EXGR_INT_cs = np.asarray(EXGR_INT_cs).reshape(4914,1)\n",
    "EXGR_INT_c = np.sum(np.multiply(np.matlib.repmat(EXGR_INT_cs, 1, ncntry),imtx_cs_c) ,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(EXGR_INT_cs_cs.columns)\n",
    "# cols = cols[-1:] + cols[:-1]\n",
    "new_cols = []\n",
    "\n",
    "for i in range(0,26):\n",
    "    key_one = i\n",
    "    new_cols.append(cols[key_one])\n",
    "    for j in range(1,189):\n",
    "        key_two = key_one + j*26\n",
    "        new_cols.append(cols[key_two])\n",
    "\n",
    "# print(cols) \n",
    "UI_exports_cs_cs = EXGR_INT_cs_cs.copy()\n",
    "UI_exports_cs_cs = UI_exports_cs_cs[cols]\n",
    "UI_exports_cs_nsec = np.sum(np.reshape(UI_exports_cs_cs.values,(ncntry*nsec, ncntry,-1), order='F'), axis=1)\n",
    "UI_exports_cs_nsec = pd.DataFrame(UI_exports_cs_nsec)\n",
    "\n",
    "UI_imports_temp = EXGR_INT_cs_cs.copy()\n",
    "UI_imports_temp = np.transpose(UI_imports_temp)\n",
    "UI_imports_cs_cs = UI_imports_temp[cols]\n",
    "UI_imports_cs_nsec = np.sum(np.reshape(UI_imports_cs_cs.values,(ncntry*nsec, ncntry,-1), order='F'), axis=1)\n",
    "UI_imports_cs_nsec = pd.DataFrame(UI_imports_cs_nsec)\n",
    "\n",
    "# print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI_exports_cs_nsec.iloc[2028:2053,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI_imports_cs_nsec.iloc[2028:2053,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_cols[0:190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:75: RuntimeWarning: divide by zero encountered in true_divide\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# % Gross exports of final demand goods and services from domestic\n",
    "# sector s in country c\n",
    "\n",
    "EXGR_FNL_cs_c =np.multiply(GRTR_FNL_cs_c ,(np.ones((ncntry*nsec,ncntry)) - imtx_cs_c))\n",
    "EXGR_FNL_cs = np.sum(np.multiply(GRTR_FNL_cs_c , (np.ones((ncntry*nsec,ncntry)) - imtx_cs_c)), axis =1)\n",
    "temp_EXGR_FNL_cs = EXGR_FNL_cs.copy()\n",
    "EXGR_FNL_cs = np.asarray(EXGR_FNL_cs).reshape(4914,1)\n",
    "\n",
    "EXGR_FNL_c = np.sum(np.multiply(np.matlib.repmat(EXGR_FNL_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "EXGR_cs_c = EXGR_INT_cs_c + EXGR_FNL_cs_c\n",
    "EXGR_c_c = np.dot(imtx_c_cs,EXGR_cs_c)\n",
    "\n",
    "# % Total gross exports (country-sector x 1)\n",
    "EXGR_cs = temp_EXGR_INT_cs + temp_EXGR_FNL_cs\n",
    "\n",
    "# % Total gross exports (country x 1)\n",
    "EXGR_c = EXGR_INT_c + EXGR_FNL_c\n",
    "\n",
    "# %% (F) Gross Imports: (Imported Intermediates)\n",
    "# % Gross Imports of Intermediates (by country-sector, and by country)\n",
    "\n",
    "IMGR_INT_cs = np.sum(np.multiply(GRTR_INT_cs_cs,(np.ones((ncntry*nsec,ncntry*nsec))-imtx_cs_cs)),axis =0)\n",
    "IMGR_INT_cs = np.asarray(IMGR_INT_cs).reshape(4914,1)\n",
    "IMGR_INT_c = np.sum(np.multiply(np.matlib.repmat(IMGR_INT_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "\n",
    "\n",
    "#  % Gross Imports of Final Demand goods and services (by country)\n",
    "IMGR_FNL_c = np.sum(np.multiply(GRTR_FNL_cs_c, (np.ones((ncntry*nsec,ncntry))-imtx_cs_c)), axis = 0)\n",
    "\n",
    "# % Total gross imports (by country)\n",
    "IMGR_c = IMGR_INT_c + IMGR_FNL_c\n",
    "#an array of 189 elements\n",
    "\n",
    "# %% (G) Gross trade balance\n",
    "    \n",
    "BALGR_c = EXGR_c - IMGR_c\n",
    "\n",
    "# %% (H) Demand for Domestic Inputs (Use of Domestic Intermediates)\n",
    "    \n",
    "# % Gross Domestic Intermediate demand for domestic inputs by country-sector\n",
    "DDGR_INT_cs = np.sum(np.multiply(GRTR_INT_cs_cs , imtx_cs_cs),axis = 0)\n",
    "DDGR_INT_cs = np.asarray(DDGR_INT_cs).reshape(4914,1)\n",
    "DDGR_INT_c = np.sum(np.multiply(np.matlib.repmat(DDGR_INT_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "\n",
    "\n",
    "# % Gross Domestic Final demand of domestic inputs by country-sector\n",
    "DDGR_FNL_c = np.sum(np.multiply(GRTR_FNL_cs_c,imtx_cs_c),axis = 0)\n",
    "\n",
    "\n",
    "# %% (I) Domestic and Foreign Final Demand\n",
    "\n",
    "GRTR_FNL_DOM_cs_c = np.multiply(GRTR_FNL_cs_c,imtx_cs_c)\n",
    "GRTR_FNL_DOM_cs = np.sum(GRTR_FNL_DOM_cs_c,axis = 1)\n",
    "\n",
    "# B)  Without statistical discrepancy\n",
    "\n",
    "# % By sector\n",
    "GRTR_FNL_DOM_cs_ck = np.multiply(data_FD.iloc[0:ncntry*nsec,0:ncntry*nfd], imtx_cs_ck)\n",
    "# % Sum across the thrid dimension, across countries for each of the 6 components of final demand\n",
    "GRTR_FNL_DOM_cs_nfd = np.sum(np.reshape(GRTR_FNL_DOM_cs_ck.values,(ncntry*nsec,nfd,-1),order='F'),axis = 2)\n",
    "\n",
    "\n",
    "GRTR_FNL_FOR_cs_c = np.multiply(GRTR_FNL_cs_c , (np.ones((ncntry*nsec,ncntry))-imtx_cs_c))\n",
    "GRTR_FNL_FOR_cs = np.sum(GRTR_FNL_FOR_cs_c,axis=1)\n",
    "\n",
    "\n",
    "# % By sector\n",
    "GRTR_FNL_FOR_cs_ck = np.multiply(data_FD.iloc[0:ncntry*nsec,0:ncntry*nfd], (np.ones((ncntry*nsec,ncntry*nfd))-imtx_cs_ck))\n",
    "# % Sum across the thrid dimension, across countries for each of the 6 components of final demand\n",
    "GRTR_FNL_FOR_cs_nfd = np.sum(np.reshape(GRTR_FNL_FOR_cs_ck.values,(ncntry*nsec,nfd,-1),order='F'),axis=2)\n",
    "\n",
    "# %% (J) Compute the VA vector indirectly (just to check that no problems with inverses)\n",
    "\n",
    "GO_cs = np.asarray(GO_cs).reshape(4914,1)\n",
    "Amat = np.divide(GRTR_INT_cs_cs ,np.matlib.repmat(GGO_cs, 1, ncntry*nsec))\n",
    "\n",
    "Amat = Amat.fillna(0)\n",
    "Amat[Amat < 0] = 0\n",
    "\n",
    "# % VA shares\n",
    "\n",
    "va_vec_cs = np.ones((nsec*ncntry,1)) - np.asarray(np.sum(Amat,axis=0)).reshape(nsec*ncntry,1)\n",
    "V_hat = np.eye(ncntry*nsec) - np.diag(np.sum(Amat , axis=0))\n",
    "\n",
    "# % Leontief inverse\n",
    "IminusA=np.eye(ncntry*nsec)-Amat\n",
    "Bmat=np.linalg.inv(IminusA)\n",
    "# % Leontief inverse\n",
    "\n",
    "# % Total Value Added by country-sector\n",
    "BY=np.matmul(Bmat,np.sum(GRTR_FNL_cs_c,axis=1))\n",
    "va_cs= np.multiply(va_vec_cs,BY)\n",
    "\n",
    "# %% (K) DVA and FVA of gross exports (From V*B*E)\n",
    "\n",
    "TiVA_temp = np.matmul(V_hat,Bmat)\n",
    "TiVA=np.matmul( TiVA_temp,np.diag(EXGR_cs))\n",
    "\n",
    "EXGR_DVA_cs = np.sum(np.multiply(TiVA,imtx_cs_cs), axis=0)\n",
    "EXGR_DVA_cs = np.asarray(EXGR_DVA_cs).reshape(4914,1)\n",
    "\n",
    "EXGR_FVA_cs = np.sum(np.multiply(TiVA , (np.ones((ncntry*nsec,ncntry*nsec))-imtx_cs_cs)),axis=0)\n",
    "EXGR_FVA_cs = np.asarray(EXGR_FVA_cs).reshape(4914,1)\n",
    "\n",
    "# EXGR_DVA_c = np.sum(np.multiply(np.matlib.repmat(EXGR_DVA_cs, 1, ncntry), imtx_cs_c),axis=0)\n",
    "# EXGR_FVA_c = np.sum(np.multiply(np.matlib.repmat(EXGR_FVA_cs, 1, ncntry), imtx_cs_c),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXGR_DVA_cs[78*26:79*26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[263253.29372633,      0.        ,      0.        , ...,\n",
       "             0.        ,      0.        ,      0.        ],\n",
       "       [     0.        ,   1089.51021115,      0.        , ...,\n",
       "             0.        ,      0.        ,      0.        ],\n",
       "       [     0.        ,      0.        ,   4942.55170826, ...,\n",
       "             0.        ,      0.        ,      0.        ],\n",
       "       ...,\n",
       "       [     0.        ,      0.        ,      0.        , ...,\n",
       "          8417.49764958,      0.        ,      0.        ],\n",
       "       [     0.        ,      0.        ,      0.        , ...,\n",
       "             0.        ,   1090.45871115,      0.        ],\n",
       "       [     0.        ,      0.        ,      0.        , ...,\n",
       "             0.        ,      0.        ,   5699.40688534]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(EXGR_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([263253.29372633])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.diagonal(EXGR_cs,offset = 0,axis1=0, axis2=1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,928746) (4914,189) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-684ef57fd44d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[0mGO_c_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimtx_c_cs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mGO_cs_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m \u001b[0mGO_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGO_cs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncntry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimtx_cs_c\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[0mVALU_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVALU_cs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncntry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimtx_cs_c\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,928746) (4914,189) "
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "country = 'IND'\n",
    "yyyy = 2008\n",
    "data_FD, data_Q, data_T,data_VA,data_QY , label_FD,label_Q,label_T,label_VA,country_codes, country_list,industry_codes_26,industry_codes_6 = load_dataset(yyyy)\n",
    "\n",
    "FD = np.sum(np.reshape(data_FD.values,(ncntry*nsec+1, nfd,-1), order='F'),axis=1)        # 1140 columns\n",
    "FD = pd.DataFrame(FD)\n",
    "\n",
    "va_total_cs = np.sum(data_VA , axis =0)\n",
    "va_total_cs = np.asarray(va_total_cs)\n",
    "\n",
    "#Intermediate Demand\n",
    "GRTR_INT_cs_cs = data_T.iloc[0:ncntry*nsec,0:ncntry*nsec]\n",
    "#Final Demand\n",
    "GRTR_FNL_cs_c = FD.iloc[0:ncntry*nsec,0:ncntry]\n",
    "#Value added\n",
    "VALU_cs = va_total_cs[0:ncntry*nsec]\n",
    "\n",
    "#  (B) Identity matrices for summing across sectors (when calculating totals by country)\n",
    "\n",
    "imtx_cs_c= np.ones((nsec,1))\n",
    "ivector=np.ones((nsec,1))\n",
    "for i in range(0,ncntry -1):\n",
    "    imtx_cs_c = scipy.linalg.block_diag(imtx_cs_c, ivector)\n",
    "imtx_cs_c = pd.DataFrame(imtx_cs_c)\n",
    "    \n",
    "imtx_cs_cs= np.ones((nsec,nsec))\n",
    "ivector=np.ones((nsec,nsec))\n",
    "for i in range(0,ncntry -1):\n",
    "    imtx_cs_cs = scipy.linalg.block_diag(imtx_cs_cs, ivector)\n",
    "imtx_cs_cs = pd.DataFrame(imtx_cs_cs)\n",
    "\n",
    "\n",
    "imtx_c_cs= np.ones((1,nsec))\n",
    "ivector = np.ones((1,nsec))\n",
    "for i in range(0,ncntry -1):\n",
    "    imtx_c_cs = scipy.linalg.block_diag(imtx_c_cs, ivector)\n",
    "imtx_c_cs = pd.DataFrame(imtx_c_cs)\n",
    "\n",
    "\n",
    "imtx_c_c= np.eye(ncntry)\n",
    "imtx_c_c = pd.DataFrame(imtx_c_c)\n",
    "\n",
    "imtx_cs_ck= np.ones((nsec,nfd))\n",
    "ivector=np.ones((nsec,nfd))\n",
    "for i in range(0,ncntry -1):\n",
    "    imtx_cs_ck = scipy.linalg.block_diag(imtx_cs_ck, ivector)\n",
    "imtx_cs_ck = pd.DataFrame(imtx_cs_ck)\n",
    "\n",
    "#  (C) Calculating Gross Ouput (GO)\n",
    "\n",
    "# Without statistical discrepancy\n",
    "\n",
    "GO_INT_part = np.sum(np.reshape(GRTR_INT_cs_cs.values,(ncntry*nsec, nsec,-1), order='F'), axis=1)\n",
    "GO_INT_part = pd.DataFrame(GO_INT_part)\n",
    "\n",
    "GO_cs_c = GO_INT_part + GRTR_FNL_cs_c\n",
    "GO_cs = np.sum(GO_cs_c,axis=1)\n",
    "\n",
    "################################\n",
    "GGO_INT_part = np.sum(GRTR_INT_cs_cs, axis =0)\n",
    "GGO_cs = GGO_INT_part + VALU_cs\n",
    "###############################\n",
    "\n",
    "GO_c_c = np.dot(imtx_c_cs,GO_cs_c)\n",
    "GO_c = np.sum(np.multiply(np.matlib.repmat(GO_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "\n",
    "VALU_c = np.sum(np.multiply(np.matlib.repmat(VALU_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "\n",
    "Inputs_cs = np.sum(GRTR_INT_cs_cs,axis=0)\n",
    "Inputs_c = np.sum(np.multiply(np.matlib.repmat(Inputs_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "VALU_derived_cs = GO_cs - Inputs_cs\n",
    "\n",
    "\n",
    "VALU_derived_c = np.sum(np.multiply(np.matlib.repmat(VALU_derived_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "\n",
    "# (E) Gross Exports\n",
    "#  Gross exports of intermediate goods and services from domestic\n",
    "#  sector s in country c\n",
    "\n",
    "EXGR_INT_cs_cs = np.multiply(GRTR_INT_cs_cs,(np.ones((ncntry*nsec,ncntry*nsec)) - imtx_cs_cs))\n",
    "\n",
    "EXGR_INT_cs_c = np.sum(np.reshape(EXGR_INT_cs_cs.values,(ncntry*nsec, nsec,-1), order='F'), axis=1)\n",
    "EXGR_INT_cs_c = pd.DataFrame(EXGR_INT_cs_c)\n",
    "\n",
    "\n",
    "EXGR_INT_cs = np.sum(EXGR_INT_cs_c,axis = 1)\n",
    "EXGR_INT_c = np.sum(np.multiply(np.matlib.repmat(EXGR_INT_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "\n",
    "# % Gross exports of final demand goods and services from domestic\n",
    "# sector s in country c\n",
    "\n",
    "EXGR_FNL_cs_c =np.multiply(GRTR_FNL_cs_c ,(np.ones((ncntry*nsec,ncntry)) - imtx_cs_c))\n",
    "EXGR_FNL_cs = np.sum(np.multiply(GRTR_FNL_cs_c , (np.ones((ncntry*nsec,ncntry)) - imtx_cs_c)), axis =1)\n",
    "\n",
    "EXGR_FNL_c = np.sum(np.multiply(np.matlib.repmat(EXGR_FNL_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "EXGR_cs_c = EXGR_INT_cs_c + EXGR_FNL_cs_c\n",
    "EXGR_c_c = np.dot(imtx_c_cs,EXGR_cs_c)\n",
    "\n",
    "# % Total gross exports (country-sector x 1)\n",
    "EXGR_cs = EXGR_INT_cs + EXGR_FNL_cs\n",
    "\n",
    "# % Total gross exports (country x 1)\n",
    "EXGR_c = EXGR_INT_c + EXGR_FNL_c\n",
    "\n",
    "# %% (F) Gross Imports: (Imported Intermediates)\n",
    "# % Gross Imports of Intermediates (by country-sector, and by country)\n",
    "\n",
    "IMGR_INT_cs = np.sum(np.multiply(GRTR_INT_cs_cs,(np.ones((ncntry*nsec,ncntry*nsec))-imtx_cs_cs)),axis =0)\n",
    "IMGR_INT_c = np.sum(np.multiply(np.matlib.repmat(IMGR_INT_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "\n",
    "\n",
    "#  % Gross Imports of Final Demand goods and services (by country)\n",
    "IMGR_FNL_c = np.sum(np.multiply(GRTR_FNL_cs_c, (np.ones((ncntry*nsec,ncntry))-imtx_cs_c)), axis = 0)\n",
    "\n",
    "# % Total gross imports (by country)\n",
    "IMGR_c = IMGR_INT_c + IMGR_FNL_c\n",
    "#an array of 189 elements\n",
    "\n",
    "# %% (G) Gross trade balance\n",
    "    \n",
    "BALGR_c = EXGR_c - IMGR_c\n",
    "\n",
    "# %% (H) Demand for Domestic Inputs (Use of Domestic Intermediates)\n",
    "    \n",
    "# % Gross Domestic Intermediate demand for domestic inputs by country-sector\n",
    "DDGR_INT_cs = np.sum(np.multiply(GRTR_INT_cs_cs , imtx_cs_cs),axis = 0)\n",
    "DDGR_INT_c = np.sum(np.multiply(np.matlib.repmat(DDGR_INT_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "\n",
    "\n",
    "# % Gross Domestic Final demand of domestic inputs by country-sector\n",
    "DDGR_FNL_c = np.sum(np.multiply(GRTR_FNL_cs_c,imtx_cs_c),axis = 0)\n",
    "\n",
    "\n",
    "# %% (I) Domestic and Foreign Final Demand\n",
    "\n",
    "GRTR_FNL_DOM_cs_c = np.multiply(GRTR_FNL_cs_c,imtx_cs_c)\n",
    "GRTR_FNL_DOM_cs = np.sum(GRTR_FNL_DOM_cs_c,axis = 1)\n",
    "\n",
    "# B)  Without statistical discrepancy\n",
    "\n",
    "# % By sector\n",
    "GRTR_FNL_DOM_cs_ck = np.multiply(data_FD.iloc[0:ncntry*nsec,0:ncntry*nfd], imtx_cs_ck)\n",
    "# % Sum across the thrid dimension, across countries for each of the 6 components of final demand\n",
    "GRTR_FNL_DOM_cs_nfd = np.sum(np.reshape(GRTR_FNL_DOM_cs_ck.values,(ncntry*nsec,nfd,-1),order='F'),axis = 2)\n",
    "\n",
    "\n",
    "GRTR_FNL_FOR_cs_c = np.multiply(GRTR_FNL_cs_c , (np.ones((ncntry*nsec,ncntry))-imtx_cs_c))\n",
    "GRTR_FNL_FOR_cs = np.sum(GRTR_FNL_FOR_cs_c,axis=1)\n",
    "\n",
    "\n",
    "# % By sector\n",
    "GRTR_FNL_FOR_cs_ck = np.multiply(data_FD.iloc[0:ncntry*nsec,0:ncntry*nfd], (np.ones((ncntry*nsec,ncntry*nfd))-imtx_cs_ck))\n",
    "# % Sum across the thrid dimension, across countries for each of the 6 components of final demand\n",
    "GRTR_FNL_FOR_cs_nfd = np.sum(np.reshape(GRTR_FNL_FOR_cs_ck.values,(ncntry*nsec,nfd,-1),order='F'),axis=2)\n",
    "\n",
    "# %% (J) Compute the VA vector indirectly (just to check that no problems with inverses)\n",
    "\n",
    "GO_cs = np.asarray(GO_cs).reshape(4914,1)\n",
    "Amat = np.divide(GRTR_INT_cs_cs ,np.matlib.repmat(GO_cs, 1, ncntry*nsec))\n",
    "\n",
    "Amat = Amat.fillna(0)\n",
    "Amat[Amat < 0] = 0\n",
    "\n",
    "# % VA shares\n",
    "\n",
    "va_vec_cs = np.ones((nsec*ncntry,1)) - np.asarray(np.sum(Amat,axis=0)).reshape(nsec*ncntry,1)\n",
    "V_hat = np.eye(ncntry*nsec) - np.diag(np.sum(Amat , axis=0))\n",
    "\n",
    "# % Leontief inverse\n",
    "IminusA=np.eye(ncntry*nsec)-Amat\n",
    "Bmat=np.linalg.inv(IminusA)\n",
    "# % Leontief inverse\n",
    "\n",
    "# % Total Value Added by country-sector\n",
    "BY=np.matmul(Bmat,np.sum(GRTR_FNL_cs_c,axis=1))\n",
    "va_cs= np.multiply(va_vec_cs,BY)\n",
    "\n",
    "# %% (K) DVA and FVA of gross exports (From V*B*E)\n",
    "\n",
    "TiVA_temp = np.matmul(V_hat,Bmat)\n",
    "TiVA=np.matmul( TiVA_temp,np.diag(EXGR_cs))\n",
    "\n",
    "EXGR_DVA_cs = np.sum(np.multiply(TiVA,imtx_cs_cs), axis=0)\n",
    "EXGR_DVA_cs = np.asarray(EXGR_DVA_cs).reshape(4914,1)\n",
    "\n",
    "EXGR_FVA_cs = np.sum(np.multiply(TiVA , (np.ones((ncntry*nsec,ncntry*nsec))-imtx_cs_cs)),axis=0)\n",
    "EXGR_FVA_cs = np.asarray(EXGR_FVA_cs).reshape(4914,1)\n",
    "\n",
    "EXGR_DVA_c = np.sum(np.multiply(np.matlib.repmat(EXGR_DVA_cs, 1, ncntry), imtx_cs_c),axis=0)\n",
    "EXGR_FVA_c = np.sum(np.multiply(np.matlib.repmat(EXGR_FVA_cs, 1, ncntry), imtx_cs_c),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = data_T.copy()\n",
    "# # a = df.index[df < 0]\n",
    "# a=[]\n",
    "# for i in range(0, df.shape[0]):\n",
    "#     a.append(df.index[df[i] < 0])\n",
    "\n",
    "# VA_data_c = pd.DataFrame(va_total_cs)\n",
    "# VA_data_c = VA_data_c.rename( columns = { 0: 'VA'})\n",
    "# VA_data_c.iloc[78*26:78*26 + 26,]\n",
    "\n",
    "# FD.iloc[78*26:78*26 + 26,78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "country = 'IND'\n",
    "yyyy = 2008\n",
    "country_index = country_codes.index(country)\n",
    "print(country_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_FD.iloc[78*26:78*26 + 26,78*6:78*6 + 6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.arange(6)\n",
    "# b = np.arange(6)*2\n",
    "# print(a)\n",
    "# print(b)\n",
    "# a = pd.DataFrame(a)\n",
    "# b = pd.DataFrame(b)\n",
    "# c = a + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GO_cs_c.iloc[78*26:78*26 + 26,78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2.103364e+07\n",
       "1      2.653539e+07\n",
       "2      3.002335e+08\n",
       "3      7.777825e+06\n",
       "4      1.750219e+08\n",
       "           ...     \n",
       "184    7.092282e+08\n",
       "185    2.077566e+08\n",
       "186    5.689968e+07\n",
       "187    3.046734e+07\n",
       "188    3.455724e+07\n",
       "Length: 189, dtype: float64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMGR_INT_cs = np.sum(np.multiply(GRTR_INT_cs_cs,(np.ones((ncntry*nsec,ncntry*nsec))-imtx_cs_cs)),axis =0)\n",
    "GO_cs = np.sum(np.multiply(np.matlib.repmat(GO_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "GO_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87034700.32575205"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMGR_INT_cs[78*26:78*26+26]\n",
    "IMGR_INT_c[78]\n",
    "EXGR_c[78]\n",
    "EXGR_FNL_c[78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2028    1.132627e+07\n",
       "2029    2.841848e+05\n",
       "2030    1.074159e+07\n",
       "2031    1.537101e+07\n",
       "2032    3.417790e+07\n",
       "2033    2.855667e+06\n",
       "2034    5.348090e+07\n",
       "2035    1.923307e+07\n",
       "2036    3.455351e+07\n",
       "2037    6.621906e+06\n",
       "2038    9.706306e+06\n",
       "2039    4.802023e+06\n",
       "2040    1.239899e+05\n",
       "2041    1.031083e+06\n",
       "2042    7.698976e+04\n",
       "2043    9.923140e+05\n",
       "2044    2.207036e+06\n",
       "2045    5.028346e+06\n",
       "2046    9.268210e+06\n",
       "2047    8.133438e+05\n",
       "2048    6.672483e+06\n",
       "2049    2.558323e+05\n",
       "2050    1.160567e+06\n",
       "2051    2.080303e+00\n",
       "2052    5.970419e+02\n",
       "2053    7.625511e+03\n",
       "dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXGR_cs[78*26:78*26+26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.sum(GRTR_INT_cs_cs , axis = 1)\n",
    "# c =np.sum(a[0:26])\n",
    "\n",
    "# b = np.sum(GRTR_FNL_cs_c , axis = 1)\n",
    "# d = np.sum(b[0:26])\n",
    "\n",
    "# print(c+d)\n",
    "\n",
    "# GO_c = np.sum(np.multiply(np.matlib.repmat(GO_cs,1,ncntry) ,imtx_cs_c), axis=0)\n",
    "# Repmat does element wise multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding sum of values of a vector\n",
    "\n",
    "# a = np.sum(Amat.iloc[78*26:78*26+26,78*26:78*26+26], axis = 1)\n",
    "# a = np.sum(Amat.iloc[78*26:78*26+26,], axis = 1)\n",
    "# a = np.sum(Amat.iloc[:,78*26:78*26+26], axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,928746) (4914,189) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-a7e6c21abecb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;31m# np.matlib.repmat(EXGR_DVA_cs, 1, ncntry*nsec)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m \u001b[0mGO_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGO_cs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncntry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimtx_cs_c\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;31m# a = GO_cs.copy()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,928746) (4914,189) "
     ]
    }
   ],
   "source": [
    "#tic;\n",
    "start = datetime.now()\n",
    "\n",
    "# %% (A) Read in data\n",
    "# % Add appropriate file location.\n",
    "\n",
    "country = 'IND'\n",
    "yyyy = 2008\n",
    "data_FD, data_Q, data_T,data_VA,data_QY , label_FD,label_Q,label_T,label_VA,country_codes, country_list,industry_codes_26,industry_codes_6 = load_dataset(yyyy)\n",
    "\n",
    "\n",
    "# data_T = data_T.fillna(0)\n",
    "# data_T[data_T < 0] = 0\n",
    "\n",
    "# data_FD = data_FD.fillna(0)\n",
    "# data_FD[data_FD < 0] = 0\n",
    "\n",
    "#### Define the Intermediate Use and Final Demand Sections of Matrix ####\n",
    "# data_FD and data_T\n",
    "# Global bilateral gross trade matrices by exporting industry/country (y-dim, rows)\n",
    "# and importing (industry/)country (x-dim, cols) for intermediate (INT) or final (FNL) goods\n",
    "\n",
    "# % intermediate use matrix ((ncntry*nsec)+1) x ((ncntry*nsec)+1)\n",
    "# data_T\n",
    "\n",
    "# % final demand matrix ((ncntry*nsec)+1) x ((ncntry*nsec)+nfd)\n",
    "# fd = dlmread(filepath_fd,'\\t'); ........ data_FD in here\n",
    "# % Summing over all 6 components of final demand for each country [(ncntry*nsec) x ncntry]\n",
    "# FD = squeeze(sum(reshape(fd,ncntry*nsec+1,nfd,[]),2));\n",
    "\n",
    "FD = np.sum(np.reshape(data_FD.values,(ncntry*nsec+1, nfd,-1), order='F'),axis=1)        # 1140 columns\n",
    "#No need to squeeze this\n",
    "FD = pd.DataFrame(FD)\n",
    "\n",
    "\n",
    "# % value added matrix (6 x ((ncntry*nsec)+1)\n",
    "# va_components = dlmread(filepath_va,'\\t');..............data_VA in here\n",
    "# va_total_cs = sum(va_components,1)';\n",
    "\n",
    "va_total_cs = np.sum(data_VA , axis =0)\n",
    "va_total_cs = np.asarray(va_total_cs)\n",
    "\n",
    "# %% Drop the final statistical discrepancy row/column from matrix (aka Rest of World)\n",
    "# GRTR_INT_cs_cs = id(1:ncntry*nsec,1:ncntry*nsec);  % intermediate demand\n",
    "# GRTR_FNL_cs_c = FD(1:ncntry*nsec,1:ncntry);              % final demand\n",
    "# VALU_cs = va_total_cs(1:ncntry*nsec,1);\n",
    "\n",
    "#Intermediate Demand\n",
    "GRTR_INT_cs_cs = data_T.iloc[0:ncntry*nsec,0:ncntry*nsec]\n",
    "#Final Demand\n",
    "GRTR_FNL_cs_c = FD.iloc[0:ncntry*nsec,0:ncntry]\n",
    "#Value added\n",
    "VALU_cs = va_total_cs[0:ncntry*nsec]\n",
    "\n",
    "#  (B) Identity matrices for summing across sectors (when calculating totals by country)\n",
    "\n",
    "#  (B) Identity matrices for summing across sectors (when calculating totals by country)\n",
    "# Construct block diagonal matrix with blocks of ones(nsec,nsec) on the diagonal\n",
    "# import scipy.linalg\n",
    "\n",
    "imtx_cs_c= np.ones((nsec,1))\n",
    "ivector=np.ones((nsec,1))\n",
    "for i in range(0,ncntry -1):\n",
    "    imtx_cs_c = scipy.linalg.block_diag(imtx_cs_c, ivector)\n",
    "imtx_cs_c = pd.DataFrame(imtx_cs_c)\n",
    "    \n",
    "imtx_cs_cs= np.ones((nsec,nsec))\n",
    "ivector=np.ones((nsec,nsec))\n",
    "for i in range(0,ncntry -1):\n",
    "    imtx_cs_cs = scipy.linalg.block_diag(imtx_cs_cs, ivector)\n",
    "imtx_cs_cs = pd.DataFrame(imtx_cs_cs)\n",
    "\n",
    "\n",
    "imtx_c_cs= np.ones((1,nsec))\n",
    "ivector = np.ones((1,nsec))\n",
    "for i in range(0,ncntry -1):\n",
    "    imtx_c_cs = scipy.linalg.block_diag(imtx_c_cs, ivector)\n",
    "#     print(imtx_c_cs.shape)\n",
    "imtx_c_cs = pd.DataFrame(imtx_c_cs)\n",
    "\n",
    "\n",
    "imtx_c_c= np.eye(ncntry)\n",
    "imtx_c_c = pd.DataFrame(imtx_c_c)\n",
    "\n",
    "imtx_cs_ck= np.ones((nsec,nfd))\n",
    "ivector=np.ones((nsec,nfd))\n",
    "for i in range(0,ncntry -1):\n",
    "    imtx_cs_ck = scipy.linalg.block_diag(imtx_cs_ck, ivector)\n",
    "imtx_cs_ck = pd.DataFrame(imtx_cs_ck)\n",
    "\n",
    "#  (C) Calculating Gross Ouput (GO)\n",
    "#  Sum across all nsec sectors by country for intermediate demand\n",
    "#  and then add total final demand\n",
    "\n",
    "# Without statistical discrepancy\n",
    "\n",
    "GO_INT_part = np.sum(np.reshape(GRTR_INT_cs_cs.values,(ncntry*nsec, nsec,-1), order='F'), axis=1)\n",
    "GO_INT_part = pd.DataFrame(GO_INT_part)\n",
    "\n",
    "GO_cs_c = GO_INT_part + GRTR_FNL_cs_c\n",
    "GO_cs = np.sum(GO_cs_c,axis=1)\n",
    "\n",
    "# Aggregate gross output matrix across sectors [ncntry x ncntry]\n",
    "# GO_c_c = imtx_c_cs*GO_cs_c; % aggregate rows\n",
    "GO_c_c = np.dot(imtx_c_cs,GO_cs_c)\n",
    "# print(imtx_c_cs.shape)\n",
    "# # 189*4914\n",
    "# print(GO_cs_c.shape)\n",
    "# #4914*189\n",
    "\n",
    "#np.matmul doesn't work in the above as the column index of the first dataframe do not make the row index of 2nd dataframe\n",
    "\n",
    "#  Total gross output for each country-sector [ncntry*nsec x 1], sum across columns\n",
    "# GO_c = np.sum((repmat(GO_cs,1,ncntry).*imtx_cs_c),1)'; Repmat does element wise multiplication\n",
    "\n",
    "# np.matlib.repmat(EXGR_DVA_cs, 1, ncntry*nsec)\n",
    "\n",
    "GO_c = np.sum(np.multiply(np.matlib.repmat(GO_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "\n",
    "# a = GO_cs.copy()\n",
    "# b= [np.sum(a[0:26])]\n",
    "# for i in range(1,int(a.shape[0]/26)):\n",
    "#     c = i*26\n",
    "#     d = 26+i*26\n",
    "#     b.append(np.sum(a[c:d]))\n",
    "    \n",
    "# b = np.asarray(b)\n",
    "# # GO_c = np.diag(b)\n",
    "# GO_c = b.copy()\n",
    "\n",
    "# 189*189 matrix\n",
    "\n",
    "#GO_c is basically Gross Output for each country and it is arranged in a 189*189 matrix\n",
    "\n",
    "# (D) VALUE-ADDED (VALU)\n",
    "    \n",
    "# VALU_c = sum((repmat(VALU_cs,1,ncntry).*imtx_cs_c),1)';\n",
    "\n",
    "VALU_c = np.sum(np.multiply(np.matlib.repmat(VALU_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "\n",
    "# b=[]\n",
    "# a = VALU_cs.copy()\n",
    "# for i in range(0,int(a.shape[0]/26)):\n",
    "#     c = i*26\n",
    "#     d = 26+i*26\n",
    "#     b.append(np.sum(a[c:d]))\n",
    "    \n",
    "# b = np.asarray(b)\n",
    "# # VALU_c = np.diag(b)\n",
    "# VALU_c = b.copy()\n",
    "\n",
    "# %% Derived Value-Added\n",
    "    \n",
    "# % (1) Without statistical discrepancy\n",
    "\n",
    "# % Sum across rows of the Intermediate demand matrix\n",
    "# Inputs_cs = sum(GRTR_INT_cs_cs,1)';\n",
    "Inputs_cs = np.sum(GRTR_INT_cs_cs,axis=0)\n",
    "#Summing across the columns\n",
    "\n",
    "# Inputs_c = sum((repmat(Inputs_cs,1,ncntry).*imtx_cs_c),1)';\n",
    "Inputs_c = np.sum(np.multiply(np.matlib.repmat(Inputs_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "\n",
    "# b=[]\n",
    "# a = Inputs_cs.copy()\n",
    "# for i in range(0,int(a.shape[0]/26)):\n",
    "#     c = i*26\n",
    "#     d = 26+i*26\n",
    "#     b.append(np.sum(a[c:d]))   \n",
    "# b = np.asarray(b)\n",
    "# Inputs_c = b.copy()\n",
    "\n",
    "# % VA = Gross Output - Inputs\n",
    "VALU_derived_cs = GO_cs - Inputs_cs\n",
    "# VALU_derived_c = sum((repmat(VALU_derived_cs,1,ncntry).*imtx_cs_c),1)';\n",
    "\n",
    "VALU_derived_c = np.sum(np.multiply(np.matlib.repmat(VALU_derived_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "\n",
    "# b=[]\n",
    "# a = VALU_derived_cs.copy()\n",
    "# for i in range(0,int(a.shape[0]/26)):\n",
    "#     c = i*26\n",
    "#     d = 26+i*26\n",
    "#     b.append(np.sum(a[c:d]))\n",
    "# b = np.asarray(b)\n",
    "# VALU_derived_c = b.copy()\n",
    "\n",
    "# 2)  Without statistical discrepancy (RoW)\n",
    "\n",
    "\n",
    "#skipping for now\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# (E) Gross Exports\n",
    "#  Gross exports of intermediate goods and services from domestic\n",
    "#  sector s in country c\n",
    "\n",
    "# EXGR_INT_cs_cs = GRTR_INT_cs_cs.*(ones(ncntry*nsec)-imtx_cs_cs);\n",
    "EXGR_INT_cs_cs = np.multiply(GRTR_INT_cs_cs,(np.ones((ncntry*nsec,ncntry*nsec)) - imtx_cs_cs))\n",
    "\n",
    "EXGR_INT_cs_c = np.sum(np.reshape(EXGR_INT_cs_cs.values,(ncntry*nsec, nsec,-1), order='F'), axis=1)\n",
    "EXGR_INT_cs_c = pd.DataFrame(EXGR_INT_cs_c)\n",
    "\n",
    "# the below code is giving same answers as above\n",
    "\n",
    "# a = np.empty((ncntry*nsec,ncntry))\n",
    "# a[:] = np.NaN\n",
    "# a = pd.DataFrame(a)\n",
    "\n",
    "# for k in range(0,ncntry):\n",
    "#     a.iloc[:,k] = np.sum(EXGR_INT_cs_cs.iloc[:, k*nsec:nsec+ nsec*k],axis = 1)\n",
    "\n",
    "# EXGR_INT_cs_c = a.copy()\n",
    "\n",
    "EXGR_INT_cs = np.sum(EXGR_INT_cs_c,axis = 1)\n",
    "# EXGR_INT_c = sum(repmat(EXGR_INT_cs,1,ncntry).*imtx_cs_c,1)';\n",
    "\n",
    "# b=[]\n",
    "# a = EXGR_INT_cs.copy()\n",
    "# for i in range(0,int(a.shape[0]/26)):\n",
    "#     c = i*26\n",
    "#     d = 26+i*26\n",
    "#     b.append(np.sum(a[c:d]))   \n",
    "# b = np.asarray(b)\n",
    "# # EXGR_INT_c = np.diag(b)\n",
    "# EXGR_INT_c = b.copy()\n",
    "\n",
    "\n",
    "EXGR_INT_c = np.sum(np.multiply(np.matlib.repmat(EXGR_INT_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "\n",
    "# % Gross exports of final demand goods and services from domestic\n",
    "# sector s in country c\n",
    "\n",
    "# EXGR_FNL_cs_c = GRTR_FNL_cs_c.*(ones(ncntry*nsec,ncntry)-imtx_cs_c);\n",
    "EXGR_FNL_cs_c =np.multiply(GRTR_FNL_cs_c ,(np.ones((ncntry*nsec,ncntry)) - imtx_cs_c))\n",
    "# EXGR_FNL_cs = sum(GRTR_FNL_cs_c.*(ones(ncntry*nsec,ncntry)-imtx_cs_c),2);\n",
    "EXGR_FNL_cs = np.sum(np.multiply(GRTR_FNL_cs_c , (np.ones((ncntry*nsec,ncntry)) - imtx_cs_c)), axis =1)\n",
    "\n",
    "# EXGR_FNL_c = sum(repmat(EXGR_FNL_cs,1,ncntry).*imtx_cs_c,1)';\n",
    "# b=[]\n",
    "# a = EXGR_FNL_cs.copy()\n",
    "# for i in range(0,int(a.shape[0]/26)):\n",
    "#     c = i*26\n",
    "#     d = 26+i*26\n",
    "#     b.append(np.sum(a[c:d]))   \n",
    "# b = np.asarray(b)\n",
    "# # EXGR_FNL_c = np.diag(b)\n",
    "# EXGR_FNL_c = b.copy()\n",
    "EXGR_FNL_c = np.sum(np.multiply(np.matlib.repmat(EXGR_FNL_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "\n",
    "\n",
    "#  % Total gross exports (country-sector x country)\n",
    "EXGR_cs_c = EXGR_INT_cs_c + EXGR_FNL_cs_c\n",
    "EXGR_c_c = np.dot(imtx_c_cs,EXGR_cs_c)\n",
    "\n",
    "# % Total gross exports (country-sector x 1)\n",
    "EXGR_cs = EXGR_INT_cs + EXGR_FNL_cs\n",
    "#     % EXGR_cs = sum(GO_cs_c.*(ones(ncntry*nsec,ncntry)-imtx_cs_c),2);\n",
    "#     % EXGR_cs = sum(GOndom_cs_c,2);\n",
    "\n",
    "\n",
    "# % Total gross exports (country x 1)\n",
    "EXGR_c = EXGR_INT_c + EXGR_FNL_c\n",
    "#     % EXGR_c = sum(repmat(EXGR_cs,1,ncntry).*imtx_cs_c,1)';\n",
    "#     % EXGR_c = sum(EXGR_c_c,2);\n",
    "\n",
    "# %% (F) Gross Imports: (Imported Intermediates)\n",
    "# % Gross Imports of Intermediates (by country-sector, and by country)\n",
    "\n",
    "IMGR_INT_cs = np.sum(np.multiply(GRTR_INT_cs_cs,(np.ones((ncntry*nsec,ncntry*nsec))-imtx_cs_cs)),axis =0)\n",
    "# IMGR_INT_c = sum((repmat(IMGR_INT_cs,1,ncntry).*imtx_cs_c),1)'\n",
    "# b=[]\n",
    "# a = IMGR_INT_cs.copy()\n",
    "# for i in range(0,int(a.shape[0]/26)):\n",
    "#     c = i*26\n",
    "#     d = 26+i*26\n",
    "#     b.append(np.sum(a[c:d]))   \n",
    "# b = np.asarray(b)\n",
    "# IMGR_INT_c = b.copy()\n",
    "IMGR_INT_c = np.sum(np.multiply(np.matlib.repmat(IMGR_INT_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "\n",
    "\n",
    "#  % Gross Imports of Final Demand goods and services (by country)\n",
    "# IMGR_FNL_c = sum(GRTR_FNL_cs_c.*(ones(ncntry*nsec,ncntry)-imtx_cs_c),1)';\n",
    "IMGR_FNL_c = np.sum(np.multiply(GRTR_FNL_cs_c, (np.ones((ncntry*nsec,ncntry))-imtx_cs_c)), axis = 0)\n",
    "\n",
    "# % Total gross imports (by country)\n",
    "# IMGR_c = IMGR_INT_c + IMGR_FNL_c;\n",
    "IMGR_c = IMGR_INT_c + IMGR_FNL_c\n",
    "#an array of 189 elements\n",
    "\n",
    "\n",
    "# %IMGR_c = sum(GOndom,1)';\n",
    "\n",
    "# %% (G) Gross trade balance\n",
    "    \n",
    "BALGR_c = EXGR_c - IMGR_c\n",
    "\n",
    "# %% (H) Demand for Domestic Inputs (Use of Domestic Intermediates)\n",
    "    \n",
    "# % Gross Domestic Intermediate demand for domestic inputs by country-sector\n",
    "DDGR_INT_cs = np.sum(np.multiply(GRTR_INT_cs_cs , imtx_cs_cs),axis = 0)\n",
    "# DDGR_INT_c = sum((repmat(DDGR_INT_cs,1,ncntry).*imtx_cs_c),1)';\n",
    "\n",
    "# b=[]\n",
    "# a = DDGR_INT_cs.copy()\n",
    "# for i in range(0,int(a.shape[0]/26)):\n",
    "#     c = i*26\n",
    "#     d = 26+i*26\n",
    "#     b.append(np.sum(a[c:d]))   \n",
    "# b = np.asarray(b)\n",
    "# DDGR_INT_c = b.copy()\n",
    "\n",
    "DDGR_INT_c = np.sum(np.multiply(np.matlib.repmat(DDGR_INT_cs, 1, ncntry),imtx_cs_c) ,axis=0)\n",
    "\n",
    "\n",
    "# % Gross Domestic Final demand of domestic inputs by country-sector\n",
    "DDGR_FNL_c = np.sum(np.multiply(GRTR_FNL_cs_c,imtx_cs_c),axis = 0)\n",
    "\n",
    "\n",
    "# %% (I) Domestic and Foreign Final Demand\n",
    "\n",
    "GRTR_FNL_DOM_cs_c = np.multiply(GRTR_FNL_cs_c,imtx_cs_c)\n",
    "GRTR_FNL_DOM_cs = np.sum(GRTR_FNL_DOM_cs_c,axis = 1)\n",
    "\n",
    "# B)  Without statistical discrepancy\n",
    "\n",
    "# % By sector\n",
    "GRTR_FNL_DOM_cs_ck = np.multiply(data_FD.iloc[0:ncntry*nsec,0:ncntry*nfd], imtx_cs_ck)\n",
    "# % Sum across the thrid dimension, across countries for each of the 6 components of final demand\n",
    "GRTR_FNL_DOM_cs_nfd = np.sum(np.reshape(GRTR_FNL_DOM_cs_ck.values,(ncntry*nsec,nfd,-1),order='F'),axis = 2)\n",
    "\n",
    "\n",
    "GRTR_FNL_FOR_cs_c = np.multiply(GRTR_FNL_cs_c , (np.ones((ncntry*nsec,ncntry))-imtx_cs_c))\n",
    "GRTR_FNL_FOR_cs = np.sum(GRTR_FNL_FOR_cs_c,axis=1)\n",
    "\n",
    "\n",
    "# % By sector\n",
    "GRTR_FNL_FOR_cs_ck = np.multiply(data_FD.iloc[0:ncntry*nsec,0:ncntry*nfd], (np.ones((ncntry*nsec,ncntry*nfd))-imtx_cs_ck))\n",
    "# % Sum across the thrid dimension, across countries for each of the 6 components of final demand\n",
    "GRTR_FNL_FOR_cs_nfd = np.sum(np.reshape(GRTR_FNL_FOR_cs_ck.values,(ncntry*nsec,nfd,-1),order='F'),axis=2)\n",
    "\n",
    "# %% (J) Compute the VA vector indirectly (just to check that no problems with inverses)\n",
    "\n",
    "# % A matrix, input-output coefficients (share of gross output)\n",
    "# Amat = GRTR_INT_cs_cs./repmat(GO_cs,1,ncntry*nsec)'; \n",
    "\n",
    "GO_cs = np.asarray(GO_cs).reshape(4914,1)\n",
    "Amat = np.divide(GRTR_INT_cs_cs ,np.matlib.repmat(GO_cs, 1, ncntry*nsec))\n",
    "\n",
    "Amat = Amat.fillna(0)\n",
    "Amat[Amat < 0] = 0\n",
    "\n",
    "# % VA shares\n",
    "# va_vec_cs=1-sum(Amat)'; %vector of value added shares\n",
    "# V_hat= eye(ncntry*nsec) - diag(sum(Amat,1)); %diagonal matrix of value added shares\n",
    "\n",
    "va_vec_cs = np.ones((nsec*ncntry,1)) - np.asarray(np.sum(Amat,axis=0)).reshape(nsec*ncntry,1)\n",
    "V_hat = np.eye(ncntry*nsec) - np.diag(np.sum(Amat , axis=0))\n",
    "\n",
    "# % Leontief inverse\n",
    "IminusA=np.eye(ncntry*nsec)-Amat\n",
    "Bmat=np.linalg.inv(IminusA)\n",
    "# % Leontief inverse\n",
    "\n",
    "# % Total Value Added by country-sector\n",
    "BY=np.matmul(Bmat,np.sum(GRTR_FNL_cs_c,axis=1))\n",
    "va_cs= np.multiply(va_vec_cs,BY)\n",
    "\n",
    "# %% (K) DVA and FVA of gross exports (From V*B*E)\n",
    "\n",
    "TiVA_temp = np.matmul(V_hat,Bmat)\n",
    "TiVA=np.matmul( TiVA_temp,np.diag(EXGR_cs))\n",
    "\n",
    "EXGR_DVA_cs = np.sum(np.multiply(TiVA,imtx_cs_cs), axis=0)\n",
    "EXGR_DVA_cs = np.asarray(EXGR_DVA_cs).reshape(4914,1)\n",
    "\n",
    "EXGR_FVA_cs = np.sum(np.multiply(TiVA , (np.ones((ncntry*nsec,ncntry*nsec))-imtx_cs_cs)),axis=0)\n",
    "EXGR_FVA_cs = np.asarray(EXGR_FVA_cs).reshape(4914,1)\n",
    "\n",
    "EXGR_DVA_c = np.sum(np.multiply(np.matlib.repmat(EXGR_DVA_cs, 1, ncntry), imtx_cs_c),axis=0)\n",
    "EXGR_FVA_c = np.sum(np.multiply(np.matlib.repmat(EXGR_FVA_cs, 1, ncntry), imtx_cs_c),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.49504450e+06],\n",
       "       [ 2.57976118e+05],\n",
       "       [ 3.56456981e+06],\n",
       "       [-2.67163124e+06],\n",
       "       [-2.61056119e+06],\n",
       "       [ 1.29400592e+06],\n",
       "       [-1.59397523e+08],\n",
       "       [-3.68835186e+07],\n",
       "       [-8.87897532e+07],\n",
       "       [ 2.64081910e+05],\n",
       "       [ 1.29807845e+06],\n",
       "       [ 2.92938121e+06],\n",
       "       [ 3.45759366e+04],\n",
       "       [-1.89815415e+06],\n",
       "       [ 7.59466831e+04],\n",
       "       [ 8.19034365e+05],\n",
       "       [ 1.34986143e+06],\n",
       "       [ 2.98959054e+06],\n",
       "       [-1.26653200e+07],\n",
       "       [ 7.04134859e+05],\n",
       "       [ 1.45946677e+06],\n",
       "       [ 2.45006444e+05],\n",
       "       [ 7.25565989e+05],\n",
       "       [ 2.07819588e+00],\n",
       "       [ 4.23520087e+02],\n",
       "       [ 7.14753239e+03]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tic;\n",
    "start = datetime.now()\n",
    "\n",
    "# %% (A) Read in data\n",
    "# % Add appropriate file location.\n",
    "\n",
    "country = 'IND'\n",
    "yyyy = 2008\n",
    "data_FD, data_Q, data_T,data_VA,data_QY , label_FD,label_Q,label_T,label_VA,country_codes, country_list,industry_codes_26,industry_codes_6 = load_dataset(yyyy)\n",
    "\n",
    "\n",
    "# data_T = data_T.fillna(0)\n",
    "# data_T[data_T < 0] = 0\n",
    "\n",
    "# data_FD = data_FD.fillna(0)\n",
    "# data_FD[data_FD < 0] = 0\n",
    "\n",
    "#### Define the Intermediate Use and Final Demand Sections of Matrix ####\n",
    "# data_FD and data_T\n",
    "# Global bilateral gross trade matrices by exporting industry/country (y-dim, rows)\n",
    "# and importing (industry/)country (x-dim, cols) for intermediate (INT) or final (FNL) goods\n",
    "\n",
    "# % intermediate use matrix ((ncntry*nsec)+1) x ((ncntry*nsec)+1)\n",
    "# data_T\n",
    "\n",
    "# % final demand matrix ((ncntry*nsec)+1) x ((ncntry*nsec)+nfd)\n",
    "# fd = dlmread(filepath_fd,'\\t'); ........ data_FD in here\n",
    "# % Summing over all 6 components of final demand for each country [(ncntry*nsec) x ncntry]\n",
    "# FD = squeeze(sum(reshape(fd,ncntry*nsec+1,nfd,[]),2));\n",
    "\n",
    "FD = np.sum(np.reshape(data_FD.values,(ncntry*nsec+1, nfd,-1), order='F'),axis=1)        # 1140 columns\n",
    "#No need to squeeze this\n",
    "FD = pd.DataFrame(FD)\n",
    "\n",
    "\n",
    "# % value added matrix (6 x ((ncntry*nsec)+1)\n",
    "# va_components = dlmread(filepath_va,'\\t');..............data_VA in here\n",
    "# va_total_cs = sum(va_components,1)';\n",
    "\n",
    "va_total_cs = np.sum(data_VA , axis =0)\n",
    "va_total_cs = np.asarray(va_total_cs)\n",
    "\n",
    "# %% Drop the final statistical discrepancy row/column from matrix (aka Rest of World)\n",
    "# GRTR_INT_cs_cs = id(1:ncntry*nsec,1:ncntry*nsec);  % intermediate demand\n",
    "# GRTR_FNL_cs_c = FD(1:ncntry*nsec,1:ncntry);              % final demand\n",
    "# VALU_cs = va_total_cs(1:ncntry*nsec,1);\n",
    "\n",
    "#Intermediate Demand\n",
    "GRTR_INT_cs_cs = data_T.iloc[0:ncntry*nsec,0:ncntry*nsec]\n",
    "#Final Demand\n",
    "GRTR_FNL_cs_c = FD.iloc[0:ncntry*nsec,0:ncntry]\n",
    "#Value added\n",
    "VALU_cs = va_total_cs[0:ncntry*nsec]\n",
    "\n",
    "\n",
    "\n",
    "#  (B) Identity matrices for summing across sectors (when calculating totals by country)\n",
    "\n",
    "#  (B) Identity matrices for summing across sectors (when calculating totals by country)\n",
    "# Construct block diagonal matrix with blocks of ones(nsec,nsec) on the diagonal\n",
    "# import scipy.linalg\n",
    "\n",
    "imtx_cs_c= np.ones((nsec,1))\n",
    "ivector=np.ones((nsec,1))\n",
    "for i in range(0,ncntry -1):\n",
    "    imtx_cs_c = scipy.linalg.block_diag(imtx_cs_c, ivector)\n",
    "imtx_cs_c = pd.DataFrame(imtx_cs_c)\n",
    "    \n",
    "imtx_cs_cs= np.ones((nsec,nsec))\n",
    "ivector=np.ones((nsec,nsec))\n",
    "for i in range(0,ncntry -1):\n",
    "    imtx_cs_cs = scipy.linalg.block_diag(imtx_cs_cs, ivector)\n",
    "imtx_cs_cs = pd.DataFrame(imtx_cs_cs)\n",
    "\n",
    "\n",
    "imtx_c_cs= np.ones((1,nsec))\n",
    "ivector = np.ones((1,nsec))\n",
    "for i in range(0,ncntry -1):\n",
    "    imtx_c_cs = scipy.linalg.block_diag(imtx_c_cs, ivector)\n",
    "#     print(imtx_c_cs.shape)\n",
    "imtx_c_cs = pd.DataFrame(imtx_c_cs)\n",
    "\n",
    "\n",
    "imtx_c_c= np.eye(ncntry)\n",
    "imtx_c_c = pd.DataFrame(imtx_c_c)\n",
    "\n",
    "imtx_cs_ck= np.ones((nsec,nfd))\n",
    "ivector=np.ones((nsec,nfd))\n",
    "for i in range(0,ncntry -1):\n",
    "    imtx_cs_ck = scipy.linalg.block_diag(imtx_cs_ck, ivector)\n",
    "imtx_cs_ck = pd.DataFrame(imtx_cs_ck)\n",
    "\n",
    "#  (C) Calculating Gross Ouput (GO)\n",
    "#  Sum across all nsec sectors by country for intermediate demand\n",
    "#  and then add total final demand\n",
    "\n",
    "# Without statistical discrepancy\n",
    "\n",
    "GO_INT_part = np.sum(np.reshape(GRTR_INT_cs_cs.values,(ncntry*nsec, nsec,-1), order='F'), axis=1)\n",
    "GO_INT_part = pd.DataFrame(GO_INT_part)\n",
    "\n",
    "GO_cs_c = GO_INT_part + GRTR_FNL_cs_c\n",
    "GO_cs = np.sum(GO_cs_c,axis=1)\n",
    "\n",
    "# Aggregate gross output matrix across sectors [ncntry x ncntry]\n",
    "# GO_c_c = imtx_c_cs*GO_cs_c; % aggregate rows\n",
    "GO_c_c = np.dot(imtx_c_cs,GO_cs_c)\n",
    "# print(imtx_c_cs.shape)\n",
    "# # 189*4914\n",
    "# print(GO_cs_c.shape)\n",
    "# #4914*189\n",
    "\n",
    "#np.matmul doesn't work in the above as the column index of the first dataframe do not make the row index of 2nd dataframe\n",
    "\n",
    "#  Total gross output for each country-sector [ncntry*nsec x 1], sum across columns\n",
    "# GO_c = np.sum((repmat(GO_cs,1,ncntry).*imtx_cs_c),1)'; Repmat does element wise multiplication\n",
    "b=[]\n",
    "a = GO_cs.copy()\n",
    "for i in range(0,int(a.shape[0]/26)):\n",
    "    c = i*26\n",
    "    d = 26+i*26\n",
    "    b.append(np.sum(a[c:d]))\n",
    "    \n",
    "b = np.asarray(b)\n",
    "GO_c = np.diag(b)\n",
    "# 189*189 matrix\n",
    "\n",
    "#GO_c is basically Gross Output for each country and it is arranged in a 189*189 matrix\n",
    "\n",
    "# (D) VALUE-ADDED (VALU)\n",
    "    \n",
    "# VALU_c = sum((repmat(VALU_cs,1,ncntry).*imtx_cs_c),1)';\n",
    "b=[]\n",
    "a = VALU_cs.copy()\n",
    "for i in range(0,int(a.shape[0]/26)):\n",
    "    c = i*26\n",
    "    d = 26+i*26\n",
    "    b.append(np.sum(a[c:d]))\n",
    "    \n",
    "b = np.asarray(b)\n",
    "VALU_c = np.diag(b)\n",
    "\n",
    "# %% Derived Value-Added\n",
    "    \n",
    "# % (1) Without statistical discrepancy\n",
    "\n",
    "# % Sum across rows of the Intermediate demand matrix\n",
    "# Inputs_cs = sum(GRTR_INT_cs_cs,1)';\n",
    "Inputs_cs = np.sum(GRTR_INT_cs_cs,axis=0)\n",
    "\n",
    "# Inputs_c = sum((repmat(Inputs_cs,1,ncntry).*imtx_cs_c),1)';\n",
    "b=[]\n",
    "a = Inputs_cs.copy()\n",
    "for i in range(0,int(a.shape[0]/26)):\n",
    "    c = i*26\n",
    "    d = 26+i*26\n",
    "    b.append(np.sum(a[c:d]))   \n",
    "b = np.asarray(b)\n",
    "Inputs_c = np.diag(b)\n",
    "\n",
    "# % VA = Gross Output - Inputs\n",
    "VALU_derived_cs = GO_cs - Inputs_cs\n",
    "# VALU_derived_c = sum((repmat(VALU_derived_cs,1,ncntry).*imtx_cs_c),1)';\n",
    "b=[]\n",
    "a = VALU_derived_cs.copy()\n",
    "for i in range(0,int(a.shape[0]/26)):\n",
    "    c = i*26\n",
    "    d = 26+i*26\n",
    "    b.append(np.sum(a[c:d]))   \n",
    "b = np.asarray(b)\n",
    "VALU_derived_c = np.diag(b)\n",
    "\n",
    "# 2)  Without statistical discrepancy (RoW)\n",
    "\n",
    "\n",
    "#skipping for now\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# (E) Gross Exports\n",
    "#  Gross exports of intermediate goods and services from domestic\n",
    "#  sector s in country c\n",
    "\n",
    "# EXGR_INT_cs_cs = GRTR_INT_cs_cs.*(ones(ncntry*nsec)-imtx_cs_cs);\n",
    "EXGR_INT_cs_cs = np.multiply(GRTR_INT_cs_cs,(np.ones((ncntry*nsec,ncntry*nsec)) - imtx_cs_cs))\n",
    "\n",
    "# EXGR_INT_cs_c = np.sum(np.reshape(EXGR_INT_cs_cs.values,(ncntry*nsec, nsec,-1), order='F'), axis=1)\n",
    "# EXGR_INT_cs_c = pd.DataFrame(GO_INT_part)\n",
    "\n",
    "# Find out why the above code is giving wrong answers where answers should be zero\n",
    "\n",
    "a = np.empty((ncntry*nsec,ncntry))\n",
    "a[:] = np.NaN\n",
    "a = pd.DataFrame(a)\n",
    "\n",
    "for k in range(0,ncntry):\n",
    "    a.iloc[:,k] = np.sum(EXGR_INT_cs_cs.iloc[:, k*nsec:nsec+ nsec*k],axis = 1)\n",
    "\n",
    "EXGR_INT_cs_c = a.copy()\n",
    "\n",
    "EXGR_INT_cs = np.sum(EXGR_INT_cs_c,axis = 1)\n",
    "\n",
    "b=[]\n",
    "a = EXGR_INT_cs.copy()\n",
    "for i in range(0,int(a.shape[0]/26)):\n",
    "    c = i*26\n",
    "    d = 26+i*26\n",
    "    b.append(np.sum(a[c:d]))   \n",
    "b = np.asarray(b)\n",
    "# EXGR_INT_c = np.diag(b)\n",
    "EXGR_INT_c = b.copy()\n",
    "\n",
    "# % Gross exports of final demand goods and services from domestic\n",
    "# sector s in country c\n",
    "\n",
    "\n",
    "\n",
    "# EXGR_FNL_cs_c = GRTR_FNL_cs_c.*(ones(ncntry*nsec,ncntry)-imtx_cs_c);\n",
    "EXGR_FNL_cs_c =np.multiply(GRTR_FNL_cs_c ,(np.ones((ncntry*nsec,ncntry)) - imtx_cs_c))\n",
    "# EXGR_FNL_cs = sum(GRTR_FNL_cs_c.*(ones(ncntry*nsec,ncntry)-imtx_cs_c),2);\n",
    "EXGR_FNL_cs = np.sum(np.multiply(GRTR_FNL_cs_c , (np.ones((ncntry*nsec,ncntry)) - imtx_cs_c)), axis =1)\n",
    "\n",
    "b=[]\n",
    "a = EXGR_FNL_cs.copy()\n",
    "for i in range(0,int(a.shape[0]/26)):\n",
    "    c = i*26\n",
    "    d = 26+i*26\n",
    "    b.append(np.sum(a[c:d]))   \n",
    "b = np.asarray(b)\n",
    "# EXGR_FNL_c = np.diag(b)\n",
    "EXGR_FNL_c = b.copy()\n",
    "\n",
    "#  % Total gross exports (country-sector x country)\n",
    "EXGR_cs_c = EXGR_INT_cs_c + EXGR_FNL_cs_c\n",
    "EXGR_c_c = np.dot(imtx_c_cs,EXGR_cs_c)\n",
    "\n",
    "\n",
    "# % Total gross exports (country-sector x 1)\n",
    "EXGR_cs = EXGR_INT_cs + EXGR_FNL_cs\n",
    "#     % EXGR_cs = sum(GO_cs_c.*(ones(ncntry*nsec,ncntry)-imtx_cs_c),2);\n",
    "#     % EXGR_cs = sum(GOndom_cs_c,2);\n",
    "\n",
    "\n",
    "# % Total gross exports (country x 1)\n",
    "EXGR_c = EXGR_INT_c + EXGR_FNL_c\n",
    "#     % EXGR_c = sum(repmat(EXGR_cs,1,ncntry).*imtx_cs_c,1)';\n",
    "#     % EXGR_c = sum(EXGR_c_c,2);\n",
    "\n",
    "\n",
    "# %clear GOdom GX imtx3\n",
    "\n",
    "# %% (F) Gross Imports: (Imported Intermediates)\n",
    "# % Gross Imports of Intermediates (by country-sector, and by country)\n",
    "\n",
    "IMGR_INT_cs = np.sum(np.multiply(GRTR_INT_cs_cs,(np.ones((ncntry*nsec,ncntry*nsec))-imtx_cs_cs)),axis =0)\n",
    "# IMGR_INT_c = sum((repmat(IMGR_INT_cs,1,ncntry).*imtx_cs_c),1)'\n",
    "b=[]\n",
    "a = IMGR_INT_cs.copy()\n",
    "for i in range(0,int(a.shape[0]/26)):\n",
    "    c = i*26\n",
    "    d = 26+i*26\n",
    "    b.append(np.sum(a[c:d]))   \n",
    "b = np.asarray(b)\n",
    "IMGR_INT_c = b.copy()\n",
    "\n",
    "#  % Gross Imports of Final Demand goods and services (by country)\n",
    "# IMGR_FNL_c = sum(GRTR_FNL_cs_c.*(ones(ncntry*nsec,ncntry)-imtx_cs_c),1)';\n",
    "IMGR_FNL_c = np.sum(np.multiply(GRTR_FNL_cs_c, (np.ones((ncntry*nsec,ncntry))-imtx_cs_c)), axis = 0)\n",
    "\n",
    "# % Total gross imports (by country)\n",
    "# IMGR_c = IMGR_INT_c + IMGR_FNL_c;\n",
    "IMGR_c = IMGR_INT_c + IMGR_FNL_c\n",
    "#an array of 189 elements\n",
    "\n",
    "# %IMGR_c = sum(GOndom,1)';\n",
    "\n",
    "# %% (G) Gross trade balance\n",
    "    \n",
    "BALGR_c = EXGR_c - IMGR_c\n",
    "\n",
    "# %% (H) Demand for Domestic Inputs (Use of Domestic Intermediates)\n",
    "    \n",
    "# % Gross Domestic Intermediate demand for domestic inputs by country-sector\n",
    "DDGR_INT_cs = np.sum(np.multiply(GRTR_INT_cs_cs , imtx_cs_cs),axis = 0)\n",
    "# DDGR_INT_c = sum((repmat(DDGR_INT_cs,1,ncntry).*imtx_cs_c),1)';\n",
    "\n",
    "b=[]\n",
    "a = DDGR_INT_cs.copy()\n",
    "for i in range(0,int(a.shape[0]/26)):\n",
    "    c = i*26\n",
    "    d = 26+i*26\n",
    "    b.append(np.sum(a[c:d]))   \n",
    "b = np.asarray(b)\n",
    "DDGR_INT_c = b.copy()\n",
    "\n",
    "# % Gross Domestic Final demand of domestic inputs by country-sector\n",
    "DDGR_FNL_c = np.sum(np.multiply(GRTR_FNL_cs_c,imtx_cs_c),axis = 0)\n",
    "\n",
    "\n",
    "# %% (I) Domestic and Foreign Final Demand\n",
    "\n",
    "GRTR_FNL_DOM_cs_c = np.multiply(GRTR_FNL_cs_c,imtx_cs_c)\n",
    "GRTR_FNL_DOM_cs = np.sum(GRTR_FNL_DOM_cs_c,axis = 1)\n",
    "\n",
    "# B)  Without statistical discrepancy\n",
    "\n",
    "# % By sector\n",
    "GRTR_FNL_DOM_cs_ck = np.multiply(data_FD.iloc[0:ncntry*nsec,0:ncntry*nfd], imtx_cs_ck)\n",
    "# % Sum across the thrid dimension, across countries for each of the 6 components of final demand\n",
    "GRTR_FNL_DOM_cs_nfd = np.sum(np.reshape(GRTR_FNL_DOM_cs_ck.values,(ncntry*nsec,nfd,-1),order='F'),axis = 2)\n",
    "\n",
    "\n",
    "GRTR_FNL_FOR_cs_c = np.multiply(GRTR_FNL_cs_c , (np.ones((ncntry*nsec,ncntry))-imtx_cs_c))\n",
    "GRTR_FNL_FOR_cs = np.sum(GRTR_FNL_FOR_cs_c,axis=1)\n",
    "\n",
    "\n",
    "# % By sector\n",
    "GRTR_FNL_FOR_cs_ck = np.multiply(data_FD.iloc[0:ncntry*nsec,0:ncntry*nfd], (np.ones((ncntry*nsec,ncntry*nfd))-imtx_cs_ck))\n",
    "# % Sum across the thrid dimension, across countries for each of the 6 components of final demand\n",
    "GRTR_FNL_FOR_cs_nfd = np.sum(np.reshape(GRTR_FNL_FOR_cs_ck.values,(ncntry*nsec,nfd,-1),order='F'),axis=2)\n",
    "\n",
    "# %% (J) Compute the VA vector indirectly (just to check that no problems with inverses)\n",
    "\n",
    "# % A matrix, input-output coefficients (share of gross output)\n",
    "# Amat = GRTR_INT_cs_cs./repmat(GO_cs,1,ncntry*nsec)'; \n",
    "GO_cs = np.asarray(GO_cs).reshape(4914,1)\n",
    "Amat = np.divide(GRTR_INT_cs_cs ,np.matlib.repmat(GO_cs, 1, ncntry*nsec))\n",
    "\n",
    "Amat = Amat.fillna(0)\n",
    "Amat[Amat < 0] = 0\n",
    "\n",
    "# % VA shares\n",
    "# va_vec_cs=1-sum(Amat)'; %vector of value added shares\n",
    "# V_hat= eye(ncntry*nsec) - diag(sum(Amat,1)); %diagonal matrix of value added shares\n",
    "\n",
    "va_vec_cs = np.ones((nsec*ncntry,1)) - np.asarray(np.sum(Amat,axis=0)).reshape(nsec*ncntry,1)\n",
    "V_hat = np.eye(ncntry*nsec) - np.diag(np.sum(Amat , axis=0))\n",
    "\n",
    "# % Leontief inverse\n",
    "IminusA=np.eye(ncntry*nsec)-Amat\n",
    "Bmat=np.linalg.inv(IminusA)\n",
    "# % Leontief inverse\n",
    "\n",
    "# % Total Value Added by country-sector\n",
    "BY=np.matmul(Bmat,np.sum(GRTR_FNL_cs_c,axis=1))\n",
    "va_cs= np.multiply(va_vec_cs,BY)\n",
    "\n",
    "# %% (K) DVA and FVA of gross exports (From V*B*E)\n",
    "\n",
    "TiVA_temp = np.matmul(V_hat,Bmat)\n",
    "TiVA=np.matmul( TiVA_temp,np.diag(EXGR_cs))\n",
    "\n",
    "EXGR_DVA_cs = np.sum(np.multiply(TiVA,imtx_cs_cs), axis=0)\n",
    "EXGR_DVA_cs = np.asarray(EXGR_DVA_cs).reshape(4914,1)\n",
    "\n",
    "EXGR_FVA_cs = np.sum(np.multiply(TiVA , (np.ones((ncntry*nsec,ncntry*nsec))-imtx_cs_cs)),axis=0)\n",
    "EXGR_FVA_cs = np.asarray(EXGR_FVA_cs).reshape(4914,1)\n",
    "\n",
    "EXGR_DVA_c = np.sum(np.multiply(np.matlib.repmat(EXGR_DVA_cs, 1, ncntry), imtx_cs_c),axis=0)\n",
    "EXGR_FVA_c = np.sum(np.multiply(np.matlib.repmat(EXGR_FVA_cs, 1, ncntry), imtx_cs_c),axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4914, 4914)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.matlib.repmat(EXGR_DVA_cs, 1, ncntry*nsec)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4904</th>\n",
       "      <th>4905</th>\n",
       "      <th>4906</th>\n",
       "      <th>4907</th>\n",
       "      <th>4908</th>\n",
       "      <th>4909</th>\n",
       "      <th>4910</th>\n",
       "      <th>4911</th>\n",
       "      <th>4912</th>\n",
       "      <th>4913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>252416.239232</td>\n",
       "      <td>252416.239232</td>\n",
       "      <td>252416.239232</td>\n",
       "      <td>252416.239232</td>\n",
       "      <td>252416.239232</td>\n",
       "      <td>252416.239232</td>\n",
       "      <td>252416.239232</td>\n",
       "      <td>252416.239232</td>\n",
       "      <td>252416.239232</td>\n",
       "      <td>252416.239232</td>\n",
       "      <td>...</td>\n",
       "      <td>252416.239232</td>\n",
       "      <td>252416.239232</td>\n",
       "      <td>252416.239232</td>\n",
       "      <td>252416.239232</td>\n",
       "      <td>252416.239232</td>\n",
       "      <td>252416.239232</td>\n",
       "      <td>252416.239232</td>\n",
       "      <td>252416.239232</td>\n",
       "      <td>252416.239232</td>\n",
       "      <td>252416.239232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1065.603440</td>\n",
       "      <td>1065.603440</td>\n",
       "      <td>1065.603440</td>\n",
       "      <td>1065.603440</td>\n",
       "      <td>1065.603440</td>\n",
       "      <td>1065.603440</td>\n",
       "      <td>1065.603440</td>\n",
       "      <td>1065.603440</td>\n",
       "      <td>1065.603440</td>\n",
       "      <td>1065.603440</td>\n",
       "      <td>...</td>\n",
       "      <td>1065.603440</td>\n",
       "      <td>1065.603440</td>\n",
       "      <td>1065.603440</td>\n",
       "      <td>1065.603440</td>\n",
       "      <td>1065.603440</td>\n",
       "      <td>1065.603440</td>\n",
       "      <td>1065.603440</td>\n",
       "      <td>1065.603440</td>\n",
       "      <td>1065.603440</td>\n",
       "      <td>1065.603440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4788.360234</td>\n",
       "      <td>4788.360234</td>\n",
       "      <td>4788.360234</td>\n",
       "      <td>4788.360234</td>\n",
       "      <td>4788.360234</td>\n",
       "      <td>4788.360234</td>\n",
       "      <td>4788.360234</td>\n",
       "      <td>4788.360234</td>\n",
       "      <td>4788.360234</td>\n",
       "      <td>4788.360234</td>\n",
       "      <td>...</td>\n",
       "      <td>4788.360234</td>\n",
       "      <td>4788.360234</td>\n",
       "      <td>4788.360234</td>\n",
       "      <td>4788.360234</td>\n",
       "      <td>4788.360234</td>\n",
       "      <td>4788.360234</td>\n",
       "      <td>4788.360234</td>\n",
       "      <td>4788.360234</td>\n",
       "      <td>4788.360234</td>\n",
       "      <td>4788.360234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2741.354618</td>\n",
       "      <td>2741.354618</td>\n",
       "      <td>2741.354618</td>\n",
       "      <td>2741.354618</td>\n",
       "      <td>2741.354618</td>\n",
       "      <td>2741.354618</td>\n",
       "      <td>2741.354618</td>\n",
       "      <td>2741.354618</td>\n",
       "      <td>2741.354618</td>\n",
       "      <td>2741.354618</td>\n",
       "      <td>...</td>\n",
       "      <td>2741.354618</td>\n",
       "      <td>2741.354618</td>\n",
       "      <td>2741.354618</td>\n",
       "      <td>2741.354618</td>\n",
       "      <td>2741.354618</td>\n",
       "      <td>2741.354618</td>\n",
       "      <td>2741.354618</td>\n",
       "      <td>2741.354618</td>\n",
       "      <td>2741.354618</td>\n",
       "      <td>2741.354618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16811.531977</td>\n",
       "      <td>16811.531977</td>\n",
       "      <td>16811.531977</td>\n",
       "      <td>16811.531977</td>\n",
       "      <td>16811.531977</td>\n",
       "      <td>16811.531977</td>\n",
       "      <td>16811.531977</td>\n",
       "      <td>16811.531977</td>\n",
       "      <td>16811.531977</td>\n",
       "      <td>16811.531977</td>\n",
       "      <td>...</td>\n",
       "      <td>16811.531977</td>\n",
       "      <td>16811.531977</td>\n",
       "      <td>16811.531977</td>\n",
       "      <td>16811.531977</td>\n",
       "      <td>16811.531977</td>\n",
       "      <td>16811.531977</td>\n",
       "      <td>16811.531977</td>\n",
       "      <td>16811.531977</td>\n",
       "      <td>16811.531977</td>\n",
       "      <td>16811.531977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4909</th>\n",
       "      <td>18295.158969</td>\n",
       "      <td>18295.158969</td>\n",
       "      <td>18295.158969</td>\n",
       "      <td>18295.158969</td>\n",
       "      <td>18295.158969</td>\n",
       "      <td>18295.158969</td>\n",
       "      <td>18295.158969</td>\n",
       "      <td>18295.158969</td>\n",
       "      <td>18295.158969</td>\n",
       "      <td>18295.158969</td>\n",
       "      <td>...</td>\n",
       "      <td>18295.158969</td>\n",
       "      <td>18295.158969</td>\n",
       "      <td>18295.158969</td>\n",
       "      <td>18295.158969</td>\n",
       "      <td>18295.158969</td>\n",
       "      <td>18295.158969</td>\n",
       "      <td>18295.158969</td>\n",
       "      <td>18295.158969</td>\n",
       "      <td>18295.158969</td>\n",
       "      <td>18295.158969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4910</th>\n",
       "      <td>133489.648925</td>\n",
       "      <td>133489.648925</td>\n",
       "      <td>133489.648925</td>\n",
       "      <td>133489.648925</td>\n",
       "      <td>133489.648925</td>\n",
       "      <td>133489.648925</td>\n",
       "      <td>133489.648925</td>\n",
       "      <td>133489.648925</td>\n",
       "      <td>133489.648925</td>\n",
       "      <td>133489.648925</td>\n",
       "      <td>...</td>\n",
       "      <td>133489.648925</td>\n",
       "      <td>133489.648925</td>\n",
       "      <td>133489.648925</td>\n",
       "      <td>133489.648925</td>\n",
       "      <td>133489.648925</td>\n",
       "      <td>133489.648925</td>\n",
       "      <td>133489.648925</td>\n",
       "      <td>133489.648925</td>\n",
       "      <td>133489.648925</td>\n",
       "      <td>133489.648925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4911</th>\n",
       "      <td>8246.881084</td>\n",
       "      <td>8246.881084</td>\n",
       "      <td>8246.881084</td>\n",
       "      <td>8246.881084</td>\n",
       "      <td>8246.881084</td>\n",
       "      <td>8246.881084</td>\n",
       "      <td>8246.881084</td>\n",
       "      <td>8246.881084</td>\n",
       "      <td>8246.881084</td>\n",
       "      <td>8246.881084</td>\n",
       "      <td>...</td>\n",
       "      <td>8246.881084</td>\n",
       "      <td>8246.881084</td>\n",
       "      <td>8246.881084</td>\n",
       "      <td>8246.881084</td>\n",
       "      <td>8246.881084</td>\n",
       "      <td>8246.881084</td>\n",
       "      <td>8246.881084</td>\n",
       "      <td>8246.881084</td>\n",
       "      <td>8246.881084</td>\n",
       "      <td>8246.881084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4912</th>\n",
       "      <td>1065.906137</td>\n",
       "      <td>1065.906137</td>\n",
       "      <td>1065.906137</td>\n",
       "      <td>1065.906137</td>\n",
       "      <td>1065.906137</td>\n",
       "      <td>1065.906137</td>\n",
       "      <td>1065.906137</td>\n",
       "      <td>1065.906137</td>\n",
       "      <td>1065.906137</td>\n",
       "      <td>1065.906137</td>\n",
       "      <td>...</td>\n",
       "      <td>1065.906137</td>\n",
       "      <td>1065.906137</td>\n",
       "      <td>1065.906137</td>\n",
       "      <td>1065.906137</td>\n",
       "      <td>1065.906137</td>\n",
       "      <td>1065.906137</td>\n",
       "      <td>1065.906137</td>\n",
       "      <td>1065.906137</td>\n",
       "      <td>1065.906137</td>\n",
       "      <td>1065.906137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4913</th>\n",
       "      <td>5516.440683</td>\n",
       "      <td>5516.440683</td>\n",
       "      <td>5516.440683</td>\n",
       "      <td>5516.440683</td>\n",
       "      <td>5516.440683</td>\n",
       "      <td>5516.440683</td>\n",
       "      <td>5516.440683</td>\n",
       "      <td>5516.440683</td>\n",
       "      <td>5516.440683</td>\n",
       "      <td>5516.440683</td>\n",
       "      <td>...</td>\n",
       "      <td>5516.440683</td>\n",
       "      <td>5516.440683</td>\n",
       "      <td>5516.440683</td>\n",
       "      <td>5516.440683</td>\n",
       "      <td>5516.440683</td>\n",
       "      <td>5516.440683</td>\n",
       "      <td>5516.440683</td>\n",
       "      <td>5516.440683</td>\n",
       "      <td>5516.440683</td>\n",
       "      <td>5516.440683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4914 rows × 4914 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0              1              2              3     \\\n",
       "0     252416.239232  252416.239232  252416.239232  252416.239232   \n",
       "1       1065.603440    1065.603440    1065.603440    1065.603440   \n",
       "2       4788.360234    4788.360234    4788.360234    4788.360234   \n",
       "3       2741.354618    2741.354618    2741.354618    2741.354618   \n",
       "4      16811.531977   16811.531977   16811.531977   16811.531977   \n",
       "...             ...            ...            ...            ...   \n",
       "4909   18295.158969   18295.158969   18295.158969   18295.158969   \n",
       "4910  133489.648925  133489.648925  133489.648925  133489.648925   \n",
       "4911    8246.881084    8246.881084    8246.881084    8246.881084   \n",
       "4912    1065.906137    1065.906137    1065.906137    1065.906137   \n",
       "4913    5516.440683    5516.440683    5516.440683    5516.440683   \n",
       "\n",
       "               4              5              6              7     \\\n",
       "0     252416.239232  252416.239232  252416.239232  252416.239232   \n",
       "1       1065.603440    1065.603440    1065.603440    1065.603440   \n",
       "2       4788.360234    4788.360234    4788.360234    4788.360234   \n",
       "3       2741.354618    2741.354618    2741.354618    2741.354618   \n",
       "4      16811.531977   16811.531977   16811.531977   16811.531977   \n",
       "...             ...            ...            ...            ...   \n",
       "4909   18295.158969   18295.158969   18295.158969   18295.158969   \n",
       "4910  133489.648925  133489.648925  133489.648925  133489.648925   \n",
       "4911    8246.881084    8246.881084    8246.881084    8246.881084   \n",
       "4912    1065.906137    1065.906137    1065.906137    1065.906137   \n",
       "4913    5516.440683    5516.440683    5516.440683    5516.440683   \n",
       "\n",
       "               8              9     ...           4904           4905  \\\n",
       "0     252416.239232  252416.239232  ...  252416.239232  252416.239232   \n",
       "1       1065.603440    1065.603440  ...    1065.603440    1065.603440   \n",
       "2       4788.360234    4788.360234  ...    4788.360234    4788.360234   \n",
       "3       2741.354618    2741.354618  ...    2741.354618    2741.354618   \n",
       "4      16811.531977   16811.531977  ...   16811.531977   16811.531977   \n",
       "...             ...            ...  ...            ...            ...   \n",
       "4909   18295.158969   18295.158969  ...   18295.158969   18295.158969   \n",
       "4910  133489.648925  133489.648925  ...  133489.648925  133489.648925   \n",
       "4911    8246.881084    8246.881084  ...    8246.881084    8246.881084   \n",
       "4912    1065.906137    1065.906137  ...    1065.906137    1065.906137   \n",
       "4913    5516.440683    5516.440683  ...    5516.440683    5516.440683   \n",
       "\n",
       "               4906           4907           4908           4909  \\\n",
       "0     252416.239232  252416.239232  252416.239232  252416.239232   \n",
       "1       1065.603440    1065.603440    1065.603440    1065.603440   \n",
       "2       4788.360234    4788.360234    4788.360234    4788.360234   \n",
       "3       2741.354618    2741.354618    2741.354618    2741.354618   \n",
       "4      16811.531977   16811.531977   16811.531977   16811.531977   \n",
       "...             ...            ...            ...            ...   \n",
       "4909   18295.158969   18295.158969   18295.158969   18295.158969   \n",
       "4910  133489.648925  133489.648925  133489.648925  133489.648925   \n",
       "4911    8246.881084    8246.881084    8246.881084    8246.881084   \n",
       "4912    1065.906137    1065.906137    1065.906137    1065.906137   \n",
       "4913    5516.440683    5516.440683    5516.440683    5516.440683   \n",
       "\n",
       "               4910           4911           4912           4913  \n",
       "0     252416.239232  252416.239232  252416.239232  252416.239232  \n",
       "1       1065.603440    1065.603440    1065.603440    1065.603440  \n",
       "2       4788.360234    4788.360234    4788.360234    4788.360234  \n",
       "3       2741.354618    2741.354618    2741.354618    2741.354618  \n",
       "4      16811.531977   16811.531977   16811.531977   16811.531977  \n",
       "...             ...            ...            ...            ...  \n",
       "4909   18295.158969   18295.158969   18295.158969   18295.158969  \n",
       "4910  133489.648925  133489.648925  133489.648925  133489.648925  \n",
       "4911    8246.881084    8246.881084    8246.881084    8246.881084  \n",
       "4912    1065.906137    1065.906137    1065.906137    1065.906137  \n",
       "4913    5516.440683    5516.440683    5516.440683    5516.440683  \n",
       "\n",
       "[4914 rows x 4914 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2002    3.633666e+04\n",
       "2003    1.157778e+05\n",
       "2004    3.140764e+04\n",
       "2005    1.090072e+06\n",
       "2006    5.942443e+04\n",
       "            ...     \n",
       "2074    2.444154e+06\n",
       "2075    1.586040e+04\n",
       "2076    5.895311e+05\n",
       "2077    8.404598e+00\n",
       "2078    2.042020e+03\n",
       "Length: 77, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXGR_DVA_cs[77*26:77*27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.sum(Amat , axis=0)\n",
    "d = pd.DataFrame(d)\n",
    "any(d[0]>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # repmat(~BW,[1 1 3])\n",
    "# # (np.array([np.tile(~BW, (1,1)) for i in range(3)]))\n",
    "# # GO_cs.shape[0]/26\n",
    "# b_temp = GO_cs[0:nsec]\n",
    "# for i in range(1,int(GO_cs.shape[0]/nsec)):\n",
    "#     a = i*26\n",
    "#     b = 26+i*26\n",
    "#     a_temp= GO_cs[a:b]\n",
    "#     print(i)\n",
    "#     b_temp = scipy.linalg.block_diag(b_temp, a_temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_level_one = country_codes.index(country)\n",
    "# print(row_level_one)\n",
    "# b = GO_cs_c[row_level_one][78*26:78*26+26]\n",
    "# b = np.asarray(b)\n",
    "# print(b)\n",
    "# # Below is the Gross ouput for India for the year 2003\n",
    "# # Calculating this to check the results with the previous code\n",
    "\n",
    "a = [1.57172355e+08, 5.74662385e+06, 2.25672212e+07, 4.05031591e+07,\n",
    "       2.48764846e+07, 8.79122195e+06, 7.74971252e+07, 4.21970500e+07,\n",
    "       4.58387371e+07, 1.47177656e+07, 9.55426280e+06, 6.90585747e+06,\n",
    "       4.01238838e+07, 8.09807679e+07, 2.70847956e+06, 3.49095840e+07,\n",
    "       7.76427918e+07, 2.30205254e+07, 1.18618219e+08, 1.20739242e+07,\n",
    "       1.04789610e+08, 3.22931304e+07, 3.15360396e+07, 9.78171986e+04,\n",
    "       2.80736269e+07, 1.89394836e+03]\n",
    "\n",
    "b = [1.52482112e+08 5.57409910e+06 1.89831451e+07 3.55595333e+07\n",
    " 8.78758673e+06 7.86055053e+06 6.15441247e+07 3.72285452e+07\n",
    " 3.58410930e+07 1.23386745e+07 6.71624189e+06 4.96072293e+06\n",
    " 4.00864843e+07 8.07397986e+07 2.68616164e+06 3.46219307e+07\n",
    " 7.70030084e+07 2.16462553e+07 1.16023360e+08 1.18461382e+07\n",
    " 1.02778739e+08 3.22234720e+07 3.12090086e+07 9.77691042e+04\n",
    " 2.80598239e+07 1.58683409e+01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repository of useful functions\n",
    "\n",
    "a = np.arange(42).reshape((7, 6))\n",
    "a = pd.DataFrame(a)\n",
    "print(a)\n",
    "b = np.sum(np.reshape(a.values, (7, 2,-1), order='F'),axis=1)\n",
    "b = pd.DataFrame(b)\n",
    "print(b)\n",
    "\n",
    "#Repository of useful functions\n",
    "\n",
    "a = np.arange(42).reshape((7, 6))\n",
    "a = pd.DataFrame(a)\n",
    "print(a)\n",
    "#To add across columns axis must be 1\n",
    "b = np.sum(a, axis=1)\n",
    "\n",
    "import numpy.matlib\n",
    "\n",
    "a1 = np.arange(4).reshape(4,1)\n",
    "# a1 = a1.reshape(4,1)\n",
    "np.matlib.repmat(a1, 1, 2)\n",
    "\n",
    "Amat.isnull().values.any()\n",
    "Amat.isna().sum()\n",
    "Amat = Amat.fillna(0)\n",
    "df[df < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4   5\n",
      "0   0   1   2   3   4   5\n",
      "1   6   7   8   9  10  11\n",
      "2  12  13  14  15  16  17\n",
      "3  18  19  20  21  22  23\n",
      "4  24  25  26  27  28  29\n",
      "5  30  31  32  33  34  35\n",
      "6  36  37  38  39  40  41\n",
      "    0   1   2   3   4   5\n",
      "0   0   1   2   3   4   5\n",
      "1   6   7   8   9  10  11\n",
      "2  12  13  14  15  16  17\n",
      "3  18  19  20  21  22  23\n",
      "4  24  25  26  27  28  29\n",
      "5  30  31  32  33  34  35\n",
      "6  36  37  38  39  40  41\n",
      " a      0   1   2   3   4   5\n",
      "0   0   1   2   3   4   5\n",
      "1   6   7   8   9  10  11\n",
      "2  12  13  14  15  16  17\n",
      "3  18  19  20  21  22  23\n",
      "4  24  25  26  27  28  29\n",
      "5  30  31  32  33  34  35\n",
      "6  36  37  38  39  40  41\n",
      " b      0   1   2   3   4   5\n",
      "0   0   1   2   3   4   5\n",
      "1   6   7   8   9  10  11\n",
      "2  12  13  14  15  16  17\n",
      "3  18  19  20  21  22  23\n",
      "4  24  25  26  27  28  29\n",
      "5  30  31  32  33  34  35\n",
      "6  36  37  38  39  40  41\n",
      " c        0     1     2     3     4     5\n",
      "0     0     1     4     9    16    25\n",
      "1    36    49    64    81   100   121\n",
      "2   144   169   196   225   256   289\n",
      "3   324   361   400   441   484   529\n",
      "4   576   625   676   729   784   841\n",
      "5   900   961  1024  1089  1156  1225\n",
      "6  1296  1369  1444  1521  1600  1681\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(42).reshape((7, 6))\n",
    "a = pd.DataFrame(a)\n",
    "print(a)\n",
    "\n",
    "b = np.arange(42).reshape((7, 6))\n",
    "b = pd.DataFrame(b)\n",
    "print(b)\n",
    "\n",
    "c = np.multiply(a,b)\n",
    "\n",
    "print(\" a \", a)\n",
    "print(\" b \", b)\n",
    "print(\" c \", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5\n",
       "0   0   1   2   3   4   5\n",
       "1   6   7   8   9  10  11\n",
       "2  12  13  14  15  16  17\n",
       "3  18  19  20  21  22  23\n",
       "4  24  25  26  27  28  29\n",
       "5  30  31  32  33  34  35\n",
       "6  36  37  38  39  40  41"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>35</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6\n",
       "0  0   6  12  18  24  30  36\n",
       "1  1   7  13  19  25  31  37\n",
       "2  2   8  14  20  26  32  38\n",
       "3  3   9  15  21  27  33  39\n",
       "4  4  10  16  22  28  34  40\n",
       "5  5  11  17  23  29  35  41"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
